{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVBr6ARbKKrUtKEfo2RB3P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0yacinek0/nlp/blob/practice/%5Bgithub_nlp%5D_5_%EB%8B%A4%EC%A4%91_%EA%B0%90%EC%84%B1_%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 레이블의 갯수가 두개 이상인 데이터의 분류를 해보자. 그런데 한글 데이터셋을 못구해서... 일단 영어 데이터로 진행하겠다. 이 경우는 6개의 클래스가 있는 TREC 데이터를 분석할 것이며, 따라서 LABEL 필드에서 dtype을 선언할 필요가 없다."
      ],
      "metadata": {
        "id": "EqkJ8H2V0vtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive Mount"
      ],
      "metadata": {
        "id": "OczBRXqIXn6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo39NQ2JXqbX",
        "outputId": "5f3b7c6c-78cb-4204-eb15-694dd92a37eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd # 현재 경로 확인 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1tBoZtxaXq0H",
        "outputId": "57040aee-b871-4651-9f99-eb9dae057129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/논문/sentimentP/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvcNDbFoXzem",
        "outputId": "daa21104-4f87-4d3e-9600-787ac63d5a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/논문/sentimentP/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_hBVI0BXzlp",
        "outputId": "bf124e74-c68d-4532-c96b-ecd328b284ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMecab-ko-for-Google-Colab\u001b[0m/  ratings_train.txt  train_data.csv\n",
            "ratings_test.txt            test_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 패키지와 랜덤시드 설정"
      ],
      "metadata": {
        "id": "Cbv1p9Ct3t8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchtext==0.10.1 \n",
        "!pip install torch==1.8.0 torchtext==0.9.0\n",
        "\"\"\"\n",
        "아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\n",
        "\n",
        "torchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\n",
        "pip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\n",
        "\n",
        "https://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "j5_jZkVj367x",
        "outputId": "5ae9055d-ac11-4572-82d8-0f7354adee13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp38-cp38-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.5/735.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0 torchtext-0.9.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\\n\\ntorchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\\npip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\\n\\nhttps://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리\n",
        "* 레이블의 갯수가 두개 이상인 데이터의 분류를 해보자. 그런데 한글 데이터셋을 못구해서... 일단 영어 데이터로 진행하겠다. 이 경우는 6개의 클래스가 있는 TREC 데이터를 분석할 것이며, 따라서 LABEL 필드에서 dtype을 선언할 필요가 없다."
      ],
      "metadata": {
        "id": "7J-BU7987OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 내 다운로드 https://wikidocs.net/94600\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVimlTus405w",
        "outputId": "34e1617f-5c3f-4f5a-fe0b-14ae3d8359ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/논문/sentimentP/dataset/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-01-29 17:38:48--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.2, 18.205.93.0, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNJZ74DEMW&Signature=ASk%2BgITn%2FWguTpwBH2NjEAQpG1g%3D&x-amz-security-token=FwoGZXIvYXdzEBMaDD2G15TWQsBP464U9CK%2BAUekOVlWLt1kw%2B%2FjnINTrrG5XKrVAEqGa7%2F4LM7iLBkJpDpF8gDj4P3jVEGhoiuOBp3CVyNRSZpSjsytp0BNRa1o1E3buD2%2B19h2FKZb1dkc8FJPz7GCuiFf%2FANNHfltC0607VRTx7ia1x7EhiWWuqwblzYIrAssLrdiqbaA8bccnl0oeKQhdclJzqguM6O7QKl3PCj35Nf2rFKXnzNn0rryuu8x38OvIyy0is1CRHIpHLBfF%2FCCvX%2Fmn%2FLX62AoqN7angYyLTdkyeQjbZKlbc%2B%2FIde2z%2FAH3AqWt%2BpO5bxOgkEEMWVdYTTTT1cAngT4I52xAQ%3D%3D&Expires=1675015728 [following]\n",
            "--2023-01-29 17:38:48--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNJZ74DEMW&Signature=ASk%2BgITn%2FWguTpwBH2NjEAQpG1g%3D&x-amz-security-token=FwoGZXIvYXdzEBMaDD2G15TWQsBP464U9CK%2BAUekOVlWLt1kw%2B%2FjnINTrrG5XKrVAEqGa7%2F4LM7iLBkJpDpF8gDj4P3jVEGhoiuOBp3CVyNRSZpSjsytp0BNRa1o1E3buD2%2B19h2FKZb1dkc8FJPz7GCuiFf%2FANNHfltC0607VRTx7ia1x7EhiWWuqwblzYIrAssLrdiqbaA8bccnl0oeKQhdclJzqguM6O7QKl3PCj35Nf2rFKXnzNn0rryuu8x38OvIyy0is1CRHIpHLBfF%2FCCvX%2Fmn%2FLX62AoqN7angYyLTdkyeQjbZKlbc%2B%2FIde2z%2FAH3AqWt%2BpO5bxOgkEEMWVdYTTTT1cAngT4I52xAQ%3D%3D&Expires=1675015728\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.141.209, 52.216.113.131, 52.217.86.92, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.141.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-01-29 17:38:49 (11.6 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-01-29 17:40:57--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::3403:4be7, 2406:da00:ff00::22e9:9f55, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNB7NIV7XN&Signature=4trPWNYCEj18%2FphlhwIHNMbvdQc%3D&x-amz-security-token=FwoGZXIvYXdzEBMaDBwrPnrOsMxw%2BQuDOCK%2BAQ3GP40OY%2FiwlhXGOu1QWvdySaWuLjWG%2FGfKWxOHSb%2F645PWdlkrxSfZna8R69PFl5WWr3n8HR4RVzUxJ8mwoyTrn%2FMvapSHQoY8aTGuUrjKgbADmgH4ir6brohvQ6ibViJOtUMR%2BhZ%2FPq1RG9fDK7TwcNilvn771mGgo%2BtbyWl9jQoJjzxO5vWbA3Pg6H3OwE3UN%2Bl9yEdZjvrBo%2BVcMIQ5GwQHLFgKnMEy34VqgZ7t%2BDx3T%2BryIq7yWa171WAoqd%2FangYyLa8hPp1%2BZFwoEr63sQ2cWP%2FaPRpndZQSBh%2BZvD4Yje0Kh5mQNpa9kmAVKjxvLA%3D%3D&Expires=1675015858 [following]\n",
            "--2023-01-29 17:40:58--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNB7NIV7XN&Signature=4trPWNYCEj18%2FphlhwIHNMbvdQc%3D&x-amz-security-token=FwoGZXIvYXdzEBMaDBwrPnrOsMxw%2BQuDOCK%2BAQ3GP40OY%2FiwlhXGOu1QWvdySaWuLjWG%2FGfKWxOHSb%2F645PWdlkrxSfZna8R69PFl5WWr3n8HR4RVzUxJ8mwoyTrn%2FMvapSHQoY8aTGuUrjKgbADmgH4ir6brohvQ6ibViJOtUMR%2BhZ%2FPq1RG9fDK7TwcNilvn771mGgo%2BtbyWl9jQoJjzxO5vWbA3Pg6H3OwE3UN%2Bl9yEdZjvrBo%2BVcMIQ5GwQHLFgKnMEy34VqgZ7t%2BDx3T%2BryIq7yWa171WAoqd%2FangYyLa8hPp1%2BZFwoEr63sQ2cWP%2FaPRpndZQSBh%2BZvD4Yje0Kh5mQNpa9kmAVKjxvLA%3D%3D&Expires=1675015858\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.110.67, 52.217.96.188, 52.217.170.89, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.110.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  84.5MB/s    in 0.6s    \n",
            "\n",
            "2023-01-29 17:40:58 (84.5 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "KGx9Cp-0daAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext.datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kljAksY0tGCB",
        "outputId": "b4923f03-8026-4691-c06c-dfe20d5d1e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext.datasets (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext.datasets\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.determinisitic = True"
      ],
      "metadata": {
        "id": "ZRYJx-XZdhop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = torchtext.legacy.data.Field(tokenize='spacy')\n",
        "LABEL = torchtext.legacy.data.Field()"
      ],
      "metadata": {
        "id": "QTwv5fKZkRz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = datasets.TREC.splits(TEXT, LABEL, fine_grained=False)\n",
        "# train_data, test_data = torchtext.legacy.datasets.TREC(root='.', split=('train', 'test'))\n",
        "# https://huggingface.co/datasets/trec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "v8I1_qn_kSb8",
        "outputId": "adec68a8-ee5e-4b48-c675-5531d0c703a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-a063fb0d209c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTREC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfine_grained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# train_data, test_data = torchtext.legacy.datasets.TREC(root='.', split=('train', 'test'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# https://huggingface.co/datasets/trec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchtext.datasets' has no attribute 'TREC'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TREC 데이터 불러오기 에러 \n",
        "* AttributeError: module 'torchtext.datasets' has no attribute 'TREC'"
      ],
      "metadata": {
        "id": "ASXBIX2Rqpeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "metadata": {
        "id": "y_EyTZLNkShY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(valid_data), len(test_data)"
      ],
      "metadata": {
        "id": "T36iPmLzkSnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 살펴보기"
      ],
      "metadata": {
        "id": "BTi_52vTk7ZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vars(train_data[-3])"
      ],
      "metadata": {
        "id": "8xKohSBmkSr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vars(train_data[-2])"
      ],
      "metadata": {
        "id": "uiu9ejHbkSxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단어장 만들기. \n",
        "*  훈련 데이터 갯수가 많지 않아서 최대 갯수 설정은 할 필요가 없긴 하나 함"
      ],
      "metadata": {
        "id": "RTR2rJTokS3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                max_size = MAX_VOCAB_SIZE,\n",
        "                vectors = 'glove.6B.100d',\n",
        "                unk_init = torch.Tensor.normal_\n",
        "                )\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "NNFGuW65kTCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 라벨 타입\n",
        "* 데이터의 라벨은 다음과 같은 6개이다.\n",
        "\n",
        "* HUM for questions about humans\n",
        "* ENTY for questions about entities\n",
        "* DESC for questions asking you for a description\n",
        "* NUM for questions where the answer is numerical\n",
        "* LOC for questions where the answer is a location\n",
        "* ABBR for questions asking about abbreviations"
      ],
      "metadata": {
        "id": "Bi_b8mKalE6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "id": "1uud4I5DkTD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이터레이터 설정"
      ],
      "metadata": {
        "id": "prYrtgQIlLwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "JyXGfxCPkTIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_iterator)).text.shape"
      ],
      "metadata": {
        "id": "2E6JoXTWkTNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN 모델 사용"
      ],
      "metadata": {
        "id": "NsAs1feVkTRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(in_channels=1,\n",
        "                                             out_channels=n_filters,\n",
        "                                             kernel_size = (fs, embedding_dim))\n",
        "                                    for fs in filter_sizes])\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        #text = [sent_len, batch_size]\n",
        "        text = text.permute(1,0)\n",
        "        #text = [batch_size, sent_len]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch_size, sent_len, emb_dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        #embedded = [batch_size, 1, sent_len, emb_dim]\n",
        "        \n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        #conv_n = [batch_size, n_filters, sent_len - fs[n]]\n",
        "        \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        #pooled_n = [batch_size, n_filters]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "        #cat = [batch_size, n_filters * len(filter_size)]\n",
        "        \n",
        "        return self.fc(cat)"
      ],
      "metadata": {
        "id": "kIaVM4vZkTVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 하이퍼파라미터 설정. 데이터셋 사이즈가 작으므로 필터 사이즈를 작게 설정"
      ],
      "metadata": {
        "id": "4pUiNBB2kTYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [2,3,4]\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
      ],
      "metadata": {
        "id": "kPviNUCkkTcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "metadata": {
        "id": "9WpQDzcukTgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파라미터 개수 세어보기"
      ],
      "metadata": {
        "id": "ggA9EE94lbGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'이 모델은 {count_parameters(model):,}개의 훈련 가능한 파라미터가 있습니다.')"
      ],
      "metadata": {
        "id": "zqwKX9X7kTjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 훈련된 단어 벡터 적용"
      ],
      "metadata": {
        "id": "zI9jb_4Zlerg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "metadata": {
        "id": "EZu9v3pVlew5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### unk_token과 pad_token의 벡터를 0으로 만들기"
      ],
      "metadata": {
        "id": "6IrU8TbJle1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "0PLRbEl8le5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이 모델은 기존처럼 하나의 확률값을 출력으로 하는 것이 아니라 각 클래스별 확률을 출력하므로, 손실 함수를 기존 BCEWithLogitsLoss에서 CrossEntropyLoss로 수정해야한다."
      ],
      "metadata": {
        "id": "WO6uuwH5le9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "XJnpqj5HlfB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 각 클래스별 스코어를 출력으로 받으면 가장 높은 점수를 가지는 클래스를 반환하도록 하는 정확도 함수를 만들자. 다만 배치로 작업하고 있으므로, 배치의 평균으로 구하자."
      ],
      "metadata": {
        "id": "vO1IZ_uolfFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"배치별 정확도를 출력하는 함수\"\"\"\n",
        "    max_preds = preds.argmax(dim=1, keepdim=True)\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])    "
      ],
      "metadata": {
        "id": "Yy7_vxRYlfJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = torch.tensor([[5.0,0.1,0.3],[2.3,3.1,0.7]])\n",
        "pred"
      ],
      "metadata": {
        "id": "PcWxjg7IlfON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.argmax(dim=1).shape, pred.argmax(dim=1, keepdim=True).shape"
      ],
      "metadata": {
        "id": "CfNCs0PYlfSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.argmax(dim=1, keepdim=True).squeeze(1).eq(torch.tensor([1,1]))"
      ],
      "metadata": {
        "id": "_YgXo9FWlfWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련함수 만들기"
      ],
      "metadata": {
        "id": "NOFVyrcml7hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch.text)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "dmfG8xuIl9ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### eval 함수도 비슷함"
      ],
      "metadata": {
        "id": "81ASEgdQl91y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "1t4heN1Ol96r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "sa3MyZjCl9-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = eval(model, train_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut5-model.pt')\n",
        "        \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "Sujp8N5Rl-CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트셋에 검증"
      ],
      "metadata": {
        "id": "y73xsR6Fl-FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut5-model.pt'))\n",
        "\n",
        "test_loss, test_acc = eval(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "sJDLwRS2mFon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 임의의 문장에 대해 판정해보기"
      ],
      "metadata": {
        "id": "j_Ppy7q0l-Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_class(model, sentence, min_len=4):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    if len(tokenized) < min_len:\n",
        "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    preds = model(tensor)\n",
        "    max_preds = preds.argmax(dim=1)\n",
        "    return max_preds.item()    "
      ],
      "metadata": {
        "id": "3nitreEWl-LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 실제로 확인해보기"
      ],
      "metadata": {
        "id": "pbMvsjIEmJmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q = 'The one who told me the truth is Inhwan Lee.'\n",
        "pred_class = predict_class(model, q)\n",
        "print(f'Predicted class is: {pred_class} = {LABEL.vocab.itos[pred_class]}')"
      ],
      "metadata": {
        "id": "hWZtqswkmJq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = 'The central part of Korea is called Gyung-gi do.'\n",
        "pred_class = predict_class(model, q)\n",
        "print(f'Predicted class is: {pred_class} = {LABEL.vocab.itos[pred_class]}')"
      ],
      "metadata": {
        "id": "Ydcd4IrNmJu6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
