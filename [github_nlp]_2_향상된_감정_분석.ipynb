{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EqkJ8H2V0vtm"
      ],
      "authorship_tag": "ABX9TyP5VPJBKsItElRVakttFxih",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0yacinek0/nlp/blob/practice/%5Bgithub_nlp%5D_2_%ED%96%A5%EC%83%81%EB%90%9C_%EA%B0%90%EC%A0%95_%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구글 드라이브 마운팅 "
      ],
      "metadata": {
        "id": "2JVHDYztaLNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89nDbiwYaMkX",
        "outputId": "cf9b1abb-12b8-4763-b22f-d97e43d5018e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd # 현재 경로 확인 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ToTK22XpaMpc",
        "outputId": "5d0898e5-fc9d-4c20-d30c-ff78a603fc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/논문/sentimentP/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj4Cz3dqaMuj",
        "outputId": "03475a8b-6ca4-4bf5-f439-f86ed687159f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/논문/sentimentP/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VLQTFknfaMzc",
        "outputId": "a29562d2-ce17-440c-ff1d-64558c12cbe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/논문/sentimentP/dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJDqVvHFaM2k",
        "outputId": "ac70fb00-f0e5-47ec-ee6e-5bc7efa113be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMecab-ko-for-Google-Colab\u001b[0m/  ratings_train.txt  train_data.csv\n",
            "ratings_test.txt            test_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 패키지와 랜덤시드 설정"
      ],
      "metadata": {
        "id": "Cbv1p9Ct3t8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchtext==0.10.1 \n",
        "!pip install torch==1.8.0 torchtext==0.9.0\n",
        "\"\"\"\n",
        "아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\n",
        "\n",
        "torchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\n",
        "pip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\n",
        "\n",
        "https://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "j5_jZkVj367x",
        "outputId": "8bae3ba8-af1a-4252-cb22-1ffb1ead9e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp38-cp38-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.5/735.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0 torchtext-0.9.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\\n\\ntorchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\\npip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\\n\\nhttps://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1027\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "d_pchz0J3xxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리\n",
        "> Filed 지정 / KoNLPy의 은전한닢(Mecab) tokenizer 이용"
      ],
      "metadata": {
        "id": "7J-BU7987OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 내 다운로드 https://wikidocs.net/94600\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVimlTus405w",
        "outputId": "e513dcc3-a6b9-46da-d14c-f306c7d2fbc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/논문/sentimentP/dataset/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-01-29 16:45:06--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::3403:4be7, 2406:da00:ff00::22c0:3470, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNO2NLOKE6&Signature=du96%2BCy6RVO4%2FFIQpTyWxQnJvrY%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDHZzP35l9DZsZeNVfyK%2BAc9Ywl%2BWdxuWczUiJUciUlrjw7ouly%2B6ODsIzZ8PZXEqRb%2BJhKzWpMWB%2FurMbnYcHINpZFEI6DIa7nMwDaTixeyuBqv%2FRSYivCtlneWUkTLYDLc3ZmMDfXIgHtCaNYpCaYUSRjAGtLoE92et1lG5PScFHaYcguauuXWu1FiFdgOjBGI5RgnCsS9yYeQlbaZkMF4r05z6M%2FOr9N1iucRXbFjxByrdwQvvX1QcDnIq65rGxzVup4sRZC21lee7SkYopsDangYyLRuxLMPzcxvuK9GU5vMDD5IQy5a6TYoBDfoSWhy2tiU3caTtr9brxlWK0gwb6w%3D%3D&Expires=1675011886 [following]\n",
            "--2023-01-29 16:45:07--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNO2NLOKE6&Signature=du96%2BCy6RVO4%2FFIQpTyWxQnJvrY%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDHZzP35l9DZsZeNVfyK%2BAc9Ywl%2BWdxuWczUiJUciUlrjw7ouly%2B6ODsIzZ8PZXEqRb%2BJhKzWpMWB%2FurMbnYcHINpZFEI6DIa7nMwDaTixeyuBqv%2FRSYivCtlneWUkTLYDLc3ZmMDfXIgHtCaNYpCaYUSRjAGtLoE92et1lG5PScFHaYcguauuXWu1FiFdgOjBGI5RgnCsS9yYeQlbaZkMF4r05z6M%2FOr9N1iucRXbFjxByrdwQvvX1QcDnIq65rGxzVup4sRZC21lee7SkYopsDangYyLRuxLMPzcxvuK9GU5vMDD5IQy5a6TYoBDfoSWhy2tiU3caTtr9brxlWK0gwb6w%3D%3D&Expires=1675011886\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.169.177, 54.231.193.81, 52.217.100.164, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.169.177|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.15MB/s    in 0.4s    \n",
            "\n",
            "2023-01-29 16:45:08 (3.15 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-01-29 16:47:00--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::22e9:9f55, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNDBO6GQG7&Signature=9%2BiaBLF8yI%2BOGdXKqN15ujXgB8Y%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDEbtE8CaxrMU6juu8SK%2BAfyikcuKp%2FoALykWDBJLmOcUuOZkCOadwyBvhiRHV0zZeBeEKJ4TnJCjCLUr88COYXg4v8fbOR0SdlijRzBrDeNQlVfBSqh6aF6G%2Fy23V02L1lXcKC7tGjQyJTtTKRFSk%2BiWPL16MSkpGQ%2FyW1ScBF9cz5%2Bj8E0ZnlpbM2%2Fw2YB7hFXnQe8O7HKnX96LIrW2%2FyZBEFjOHTH8gF9mTYhEyRquYDwkt88%2Fsy2fjgOF7qv70nVH7kZzcxqmKChaH9Uoo8HangYyLTvbQIpQ54BGAU9lmZSoMuyWul91f5YQBrRRSC9FJ09Wwb24Nhe59jswyEvWFg%3D%3D&Expires=1675012011 [following]\n",
            "--2023-01-29 16:47:00--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNDBO6GQG7&Signature=9%2BiaBLF8yI%2BOGdXKqN15ujXgB8Y%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDEbtE8CaxrMU6juu8SK%2BAfyikcuKp%2FoALykWDBJLmOcUuOZkCOadwyBvhiRHV0zZeBeEKJ4TnJCjCLUr88COYXg4v8fbOR0SdlijRzBrDeNQlVfBSqh6aF6G%2Fy23V02L1lXcKC7tGjQyJTtTKRFSk%2BiWPL16MSkpGQ%2FyW1ScBF9cz5%2Bj8E0ZnlpbM2%2Fw2YB7hFXnQe8O7HKnX96LIrW2%2FyZBEFjOHTH8gF9mTYhEyRquYDwkt88%2Fsy2fjgOF7qv70nVH7kZzcxqmKChaH9Uoo8HangYyLTvbQIpQ54BGAU9lmZSoMuyWul91f5YQBrRRSC9FJ09Wwb24Nhe59jswyEvWFg%3D%3D&Expires=1675012011\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.50.28, 52.217.131.41, 3.5.3.159, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.50.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  32.3MB/s    in 1.5s    \n",
            "\n",
            "2023-01-29 16:47:02 (32.3 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "UtDEsT024qPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.legacy import data\n",
        "\n",
        "TEXT = torchtext.legacy.data.Field(tokenize=mecab.morphs)\n",
        "LABEL = torchtext.legacy.data.LabelField(dtype = torch.float)"
      ],
      "metadata": {
        "id": "WYA02H685GhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__\n",
        "torchtext.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F9nWfROP6dCb",
        "outputId": "34f41cf8-c30d-466c-86e5-2ba219fa624b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.9.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torchtext 내 내장된 데이터셋 이용하는게 아니므로 컬럼별 해당 Field 지정"
      ],
      "metadata": {
        "id": "Y5LgoodH5koB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fields = {'text': ('text', TEXT), 'label': ('label', LABEL)}\n",
        "# dictionary 형식; {csv 컬럼명 : (데이터 컬럼명, Field이름)}"
      ],
      "metadata": {
        "id": "piJA-nb56ttT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = data.TabularDataset.splits(\n",
        "    path = '.',\n",
        "    train = 'train_data.csv',\n",
        "    test = 'test_data.csv',\n",
        "    format = 'csv',\n",
        "    fields = fields\n",
        ")"
      ],
      "metadata": {
        "id": "zmCRdQD48RTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vars(train_data[0]), vars(train_data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70A2dcp8ZTG",
        "outputId": "86c9daa0-4529-49c7-ef7d-b89649f80e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'text': ['아', '더', '빙', '.', '.', '진짜', '짜증', '나', '네요', '목소리'],\n",
              "  'label': '0'},\n",
              " {'text': ['흠',\n",
              "   '.',\n",
              "   '..',\n",
              "   '포스터',\n",
              "   '보고',\n",
              "   '초딩',\n",
              "   '영화',\n",
              "   '줄',\n",
              "   '.',\n",
              "   '...',\n",
              "   '오버',\n",
              "   '연기',\n",
              "   '조차',\n",
              "   '가볍',\n",
              "   '지',\n",
              "   '않',\n",
              "   '구나'],\n",
              "  'label': '1'})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'훈련 데이터 수: {len(train_data)}')\n",
        "print(f'테스트 데이터 수: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPuMgbF18zEc",
        "outputId": "68e9f094-fe4c-4e36-fd9f-f61629031aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터 수: 149995\n",
            "테스트 데이터 수: 49997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 검증데이터 별도 생성"
      ],
      "metadata": {
        "id": "YmK9NEtt8-h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "metadata": {
        "id": "07qme4jX9CbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'훈련데이터 수 : {len(train_data)}')\n",
        "print(f'검증 데이터 수 : {len(valid_data)}')\n",
        "print(f'테스트 데이터 수 : {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NfnhTIh9I6Z",
        "outputId": "9c26c56b-cd03-4ed8-e302-5b2155eef33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련데이터 수 : 104996\n",
            "검증 데이터 수 : 44999\n",
            "테스트 데이터 수 : 49997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단어 벡터는 전처리된 단어 벡터를 받아보기\n",
        "> * 한글을 지원하는 fasttext.simple.300d 사용 <br>\n",
        "> * 사전훈련된 단어집에 없는 단어는 0으로 처리하는 걸 방지하기 위해 unk_init = otrch.Tensor.normal_옵션을 줌"
      ],
      "metadata": {
        "id": "UeQYq6Gek346"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 총 단어의 수 확인"
      ],
      "metadata": {
        "id": "sCiduXqL849A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size=MAX_VOCAB_SIZE,\n",
        "                 vectors = 'fasttext.simple.300d',\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "Qsk45f7_-MTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(TEXT.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6izlknClmYP",
        "outputId": "8d6d7ce7-1eb0-43e6-9647-57357c5f958f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25002"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL.vocab.stoi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX-JUcdHln8p",
        "outputId": "51e45890-a973-46b4-edd0-e56e5681f1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None, {'0': 0, '1': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars(train_data.examples[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oyBz15Rlryw",
        "outputId": "55f9e15e-31e1-43f7-c6e9-2f882025422e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['정신',\n",
              "  '적',\n",
              "  '인',\n",
              "  '문제',\n",
              "  '는',\n",
              "  '반드시',\n",
              "  '무조건',\n",
              "  '치료',\n",
              "  '로',\n",
              "  '해결',\n",
              "  '을',\n",
              "  '해야',\n",
              "  '한다',\n",
              "  '!'],\n",
              " 'label': '0'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_data)):\n",
        "  if len(train_data.examples[i].text)==0:\n",
        "     print(i)"
      ],
      "metadata": {
        "id": "uDuznBpslu9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BuketIterator를 이용하여 데이터 생성자 만들기\n",
        "* 데이터 생성자를 만드는데, 길이에 따라 정렬하도록 sort_within_batch = True옵션을 넣어줄 것을 원 튜토리얼에서 요구하나\n",
        "* 한글 데이터에선 오류가 발생하여 sort_key=lambda x:len(x.text) 문장을 먼저 넣어줘야 오류없이 작동함"
      ],
      "metadata": {
        "id": "q2py_-SKaX8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    # sort_within_batch = True,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "D5ZmsBZiaccO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 패딩 제외 길이로 정렬된 (문장, 길이) 순의 데이터로 이루어져있음"
      ],
      "metadata": {
        "id": "rak9IFCrmxS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_iterator)).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWgr5g7cmqGo",
        "outputId": "06c260ab-0938-4eed-9af4-a16db4415daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   28,    47,   142,   376,   163,  1249,    97,    28,   260,   166,\n",
              "           106,   187,   646,   612,    76,    47, 11192,  1073,  2445, 11052,\n",
              "           219,  5255, 14654,   267,  2477,  3583,   131,   692,  1407,     3,\n",
              "         22226,  8621,  6741,   131,   453,   926,   264,  7417,  3226,  4597,\n",
              "          4249,    17,   861,    32, 12684,  1314, 11745,   539,    28,   101,\n",
              "            16,   993,    47,   191,  3552,  1071,    41,   227,    67,  1484,\n",
              "          3431,  1325,   257,   114],\n",
              "        [  199,   189,    36,   237,    98,  4370,     2,     4,   161,    10,\n",
              "            11,   167,    84,     5,   160,   111,    11,   534,    10,    16,\n",
              "             4,    10,  2302,     2,  1349,    36,   490,     0,   214,     5,\n",
              "          1151,  9809,   216,     5,   340,     9,    12,   925,     8, 10229,\n",
              "            14,  1173,   194,   106,    40,  2021,     3,   208,     9,     0,\n",
              "           643,    95,    42,  3364,   197,  3248,     2,   371,    11,     8,\n",
              "            13,  1325,    20,    24],\n",
              "        [    4,   242,   550,     5,  1568,     3,    82,   172,  2499,     5,\n",
              "           200,   408,   269,    48,    50,    29,   214,   172,  2349,   354,\n",
              "           430,  2553,     2,     2,  9836,   692,   362, 14497,    56,     4,\n",
              "            22,     2,    13,   214,   198,  1963,   119,  2361,   125,   216,\n",
              "            10,   435,  2142,   399,  2057,  5049, 23938,   238,  3545,  6811,\n",
              "            13,  6589,    38,  8911,   300,     8,    17,   796,   248,     7,\n",
              "           311,  1325,     3,     6],\n",
              "        [   32,   432,  1168,    11,    74,   105,   172,   111,  2401,   308,\n",
              "            25,    42,    33,   162,   138,     6,    18,    48,    14,    10,\n",
              "           783,    16,    17,    70,   140,     7,    52,  1182,    31,   107,\n",
              "            22,     2,   255,  3285,   409,    18,    33,   314,     9,    13,\n",
              "            69,    25,     5,    72,   231,    30,    13,    14,   587,   206,\n",
              "          1628,   462, 20026,    66,    18,   744,    36,    64,    27, 11306,\n",
              "           248,  1325,    32,     2],\n",
              "        [  111,     3,    10,   261,    98,   955,   116,    22,  2644,    70,\n",
              "             6,    29,    31,   174,  8798,   370,   402,   326,  2463,   120,\n",
              "            42,  6333,     5,    18,     3,  4141,    58, 14497,   136,   240,\n",
              "            55,  1376,   122,     2,    11,    16,    48,     6,    92,   112,\n",
              "          1478,     4,   110, 13241,    20,    10,     8,  1762,   622,   840,\n",
              "           784,    10,    13,    10,   854,    78,   115,  4429,    41,    25,\n",
              "          6273, 14383,    27,     2],\n",
              "        [   29,   804,   185,    28,    29,     8,     6,     9,   732,    39,\n",
              "             2,    31,    42,    42,   500,    22,    31,    42,  1242, 19527,\n",
              "            18,     3,     0,    24,    32,     8,    42,  1152,    13,     3,\n",
              "           318,     6,   135,   209,    99,  3300,     2,   925,    35,    45,\n",
              "           216,   569,    66, 10429,    14,  3860,  1812,     8,    12,  1902,\n",
              "            33,   140,   127,  3384,   865,     2,    71,   295,     8,     4,\n",
              "            35, 14383,    41,   227],\n",
              "        [   71,     8,     3,     2,   118,     6,     2,    55,     6,     2,\n",
              "            76,     2,    43,    38,     2,   648,    61,     6,     2,   212,\n",
              "            33,  5907,     9,    29,    27,     6,    38,   143,     0,     6,\n",
              "             2,     2,   544,     2,   145,    10,    17,  2361,    63,   444,\n",
              "            13,    80,     6,  1162,   614,  1112,    26,     6,   175,   126,\n",
              "             6,  1866,  1570,     3,    63,     0,     2, 10561,     4,     0,\n",
              "            63,    21,     8,    68],\n",
              "        [    5,   212,     6,  1418,   222,     2,     2,    38,  9174,    17,\n",
              "            45,     2,    58,    21,     2,     0,   126,     2,     2,     2,\n",
              "            78,     2,   306,    52,     6,     2,    80,  1152,    58,     2,\n",
              "            82,     2,   138,   306,    26,   272,   443,  2597,     5,   307,\n",
              "            58,    58,    21,   407,   764,     2, 10369,     2,    26,   452,\n",
              "             2,    21,   146,     6,     5,  8061,    17,   213,     5,     2,\n",
              "          1699,   535,    43,   209]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 생성\n",
        "* multi-layered bi-directional LSTM 사용\n",
        "* dropout 적용\n",
        "* nn.utils.rnn.packed_padded_sequence 써서 패킹/언패킹 처리\n",
        "<br>\n",
        "* 최종 hidden size는 [num layers*num directions, batch size, hidden dim]임\n",
        "* 구체적으로 [forward_layer_0, backward_layer_0, forward_layer_1, backward_layer1, ..., forward_layer_n, backward_layer n] 같이 출력.\n",
        "* 꼭대기층의 hidden만 필요하므로 hidden[-2::]과 hidden[-1::]만 뽑아 concatenate할 예정"
      ],
      "metadata": {
        "id": "F5dd6y9kmu5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "wnXV66_8n0LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = nn.Embedding(3,5,padding_idx=1) \n",
        "test = torch.tensor([0, 1, 2])"
      ],
      "metadata": {
        "id": "FUthbp0Xn75v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb(test) # padding_idx에 해당하는 벡터는 0임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJSnA-tIoKJL",
        "outputId": "0704055c-d292-4f17-c7c3-d7f8a2b94c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5421,  0.3857,  0.9083, -1.1629,  0.2727],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.1429, -0.0602, -0.0263, -0.8012, -1.6145]],\n",
              "       grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_shape(name, data):\n",
        "  print(f'{name} has shape {data.shape}')"
      ],
      "metadata": {
        "id": "eTdTCawxoZoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
        "                n_layers, bidirectional, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
        "                          bidirectional=bidirectional, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        # text = [sent_len, batch_size]\n",
        "        #print_shape('text',text)\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # embedded = [sent_len, batch_size, emb_dim]\n",
        "        #print_shape('embedded', embedded)\n",
        "        \n",
        "        # pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        #print_shape('packed_output', packed_output)\n",
        "        #print_shape('hidden', hidden)\n",
        "        #print_shape('cell', cell)\n",
        "        \n",
        "        # unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        #print_shape('output', output)\n",
        "        #print_shape('output_lengths', output_lengths)        \n",
        "        \n",
        "        # output = [sent_len, batch_size, hi_dim * num_directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "        # hidden = [num_layers * num_directions, batch_size, hid_dim]\n",
        "        # cell = [num_layers * num_directions, batch_size, hid_dim]\n",
        "        \n",
        "        # concat the final forward and backward hidden layers\n",
        "        # and apply dropout\n",
        "        \n",
        "        #print_shape('hidden[-2,:,:]', hidden[-2,:,:])\n",
        "        #print_shape('hidden[-1,:,:]', hidden[-1,:,:])\n",
        "        #cat = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        #print_shape('cat', cat)\n",
        "\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "        #print_shape('hidden', hidden)\n",
        "        # hidden = [batch_size, hid_dim * num_directions]\n",
        "        \n",
        "        res = self.fc(hidden)\n",
        "        #print_shape('res', res)\n",
        "        return res"
      ],
      "metadata": {
        "id": "yQdEbHyfEdKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 하이퍼파라미터 설정"
      ],
      "metadata": {
        "id": "cNJ8LFt3EiEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300 # fasttext dim과 동일하게 설정\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
      ],
      "metadata": {
        "id": "_P4vTUoXElHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "           N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)"
      ],
      "metadata": {
        "id": "vPIklE2YEl0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파라미터 갯수 세보기 \n",
        "* 앞 모델과 비교하여 월등하게 많은 파라미터 수를 확인할 수 있음 "
      ],
      "metadata": {
        "id": "Nk7xlSlBEm7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'이 모델은 {count_parameters(model):,} 개의 파라미터를 가지고 있다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49cYtE89Euyc",
        "outputId": "7f8250b7-3346-41ff-c6b9-261fcf7dfe16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 모델은 10,220,857 개의 파라미터를 가지고 있다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 학습된 fasttxt모델의 단어 벡터를 embedding 레이어에 복사하여 담기"
      ],
      "metadata": {
        "id": "2oO_q2jOE0D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHzG4McIE75e",
        "outputId": "b72501fe-3471-469b-82a6-dd35c0087af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25002, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dimension 체크"
      ],
      "metadata": {
        "id": "W7reE5BKE9z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez4cML8FFAig",
        "outputId": "aa3c06a4-6713-48f5-f36e-0d610e30cb41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([25002, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### weight가 아니라 weight.data 에 덮어씌워야 한다는 걸 명심"
      ],
      "metadata": {
        "id": "edzGvXuhFGBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings) # copy_ 메서드는 인수를 현재 모델의 웨이트에 복사함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3j62hVKFCKL",
        "outputId": "c9833ee3-b852-41a9-d92b-ef95e73152e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1297e-01,  1.2156e+00,  6.8516e-01,  ..., -5.2034e-01,\n",
              "         -1.6626e-01, -8.4676e-04],\n",
              "        [ 9.0628e-01,  3.6853e-01, -6.4057e-01,  ...,  7.0754e-01,\n",
              "          6.3230e-01,  3.6939e-01],\n",
              "        [ 5.6857e-02, -5.1956e-02,  2.7326e-01,  ..., -6.9453e-02,\n",
              "         -1.6064e-01, -9.8923e-02],\n",
              "        ...,\n",
              "        [ 1.6462e-01,  3.1504e-01, -2.1961e-01,  ...,  1.2704e+00,\n",
              "          3.3490e-02,  6.4178e-01],\n",
              "        [ 9.2339e-01,  6.3520e-01, -8.0703e-01,  ...,  4.7187e-02,\n",
              "          9.4318e-01,  1.3437e+00],\n",
              "        [-3.4884e-01,  1.5506e+00, -3.0697e-01,  ..., -9.4593e-01,\n",
              "          5.8037e-01,  7.7458e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### unk와 pad는 수동으로 0벡터로 만들자."
      ],
      "metadata": {
        "id": "Pcsp2MzPFSJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "UNK_IDX, PAD_IDX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a92ddv-CFWgv",
        "outputId": "27607aa9-1c33-4bdd-fd11-b5736ebb8b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bgq8Vw2HFYv7",
        "outputId": "5dfc3018-bec9-4c0b-afa4-9ccc1fb2cff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0569, -0.0520,  0.2733,  ..., -0.0695, -0.1606, -0.0989],\n",
            "        ...,\n",
            "        [ 0.1646,  0.3150, -0.2196,  ...,  1.2704,  0.0335,  0.6418],\n",
            "        [ 0.9234,  0.6352, -0.8070,  ...,  0.0472,  0.9432,  1.3437],\n",
            "        [-0.3488,  1.5506, -0.3070,  ..., -0.9459,  0.5804,  0.7746]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pad는 pad_idx 옵션 때문에 훈련 내내 0으로 남아있지만 unk는 학습될 것!"
      ],
      "metadata": {
        "id": "p0hiZeN9FZun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습\n",
        "> adam으로 학습 "
      ],
      "metadata": {
        "id": "RgnvNF3GmvIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "8Ei3Yi1FFgoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 손실 함수는 binary cross entropy with logits로 하자. 이 함수는 임의의 실수를 입력으로 받아서 sigmoid 함수를 취해 0과 1 사이의 값으로 변환한 뒤 label과의 binary cross entropy를 계산"
      ],
      "metadata": {
        "id": "uoLU1wVqF41v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "QV20RV_uFguq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 평가를 위해 임의의 실수를 0과 1 두 정수 중 하나로 변환하는 함수"
      ],
      "metadata": {
        "id": "YNnsOjOdFg1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds==y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "bxsLMkj1GC1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 함수. 현재 batch.text 는 (토큰들,문장 길이) 로 구성되어 있으니 분리"
      ],
      "metadata": {
        "id": "ZC3lZ8U0GER9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text, text_lengths = batch.text\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        #print_shape('predictions',predictions)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        #print_shape('loss',loss)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "hJvd-wlFGHem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 평가를 위한 함수는 그래디언트 업데이트를 하지 않아야 하므로 with torch.no_grad(): 구문으로 감싸도록 한다. 또한 드랍아웃을 평가 때는 적용하지 않아야 하므로 model.eval() 을 넣어주어야 함"
      ],
      "metadata": {
        "id": "NDokJdW5GLNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)#.squeeze(0))\n",
        "            acc = binary_accuracy(predictions, batch.label)#.squeeze(0))\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "4sk3YzxaGNs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 에폭마다 걸린 훈련시간을 측정하는 함수 "
      ],
      "metadata": {
        "id": "q3ypgmA1GOkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "xoQBlk5EGR4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 "
      ],
      "metadata": {
        "id": "oWYVsAQGG2yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "        \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "vvJH4wQhG4P5",
        "outputId": "72218c61-e8f1-4394-fc6e-dd8a9f139c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-79c67bea96a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-ef8851818a63>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#print_shape('predictions',predictions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트셋의 결과"
      ],
      "metadata": {
        "id": "ZMqj21n1HBjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "eGjDwehFHC4P",
        "outputId": "71293137-e433-404f-8440-127b3eaf4668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-fa06022f1dca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tut2-model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tut2-model.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 더 훈련시켜보기"
      ],
      "metadata": {
        "id": "9YQ25el9HD7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "        \n",
        "    print(f'Epoch: {epoch+6:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "J9x6vzA_HF48",
        "outputId": "6eda2302-65a0-46a8-88b4-d8be248748d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-b4b4a6f23f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-ef8851818a63>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#print_shape('predictions',predictions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "63I_P71FHHEk",
        "outputId": "1bb623c9-9ca3-4049-9fce-58a7bc87415b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-fa06022f1dca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tut2-model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tut2-model.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사용자 데이터 사용\n",
        "영화 평가 데이터 직접 넣어보자.\n",
        "\n",
        "다음 기능을 하는 predict_sentiment 함수를 만들자.\n",
        "\n",
        "sets the model to evaluation mode\n",
        "tokenizes the sentence, i.e. splits it from a raw string into a list of tokens\n",
        "indexes the tokens by converting them into their integer representation from our vocabulary\n",
        "gets the length of our sequence\n",
        "converts the indexes, which are a Python list into a PyTorch tensor\n",
        "add a batch dimension by unsqueezeing\n",
        "converts the length into a tensor\n",
        "squashes the output prediction from a real number between 0 and 1 with the sigmoid function\n",
        "converts the tensor holding a single value into an integer with the item() method"
      ],
      "metadata": {
        "id": "Pu61xq10nEII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "TrsGoFe2m3J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok for tok in mecab.morphs(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1) # 배치 \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()"
      ],
      "metadata": {
        "id": "d6v7lNFzm36e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(model, \"이 영화 진짜 재밌었다!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF3rq3-Zm4Cb",
        "outputId": "06c3fc3f-fdde-4c25-bd24-96a816a9607a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5172811150550842"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(model, \"영화관에서 이걸 본 내가 바보다. 내 돈 돌려줘!!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj-BhKMOm4Ic",
        "outputId": "9ed82498-fc31-4bdc-cd08-68ec148a8ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5100839138031006"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}