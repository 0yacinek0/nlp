{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1D+5jgFbg3Aa0fYkA/mXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0yacinek0/nlp/blob/practice/%5Bgithub_nlp%5D_3_%EB%B9%A0%EB%A5%B8_%EA%B0%90%EC%A0%95%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이 튜토리얼에서는 FastText 모델을 이용해서 모델을 경량화해보자\n",
        "\n",
        "FastText 논문의 핵심 아이디어 중 하나는 입력 문장의 마지막에 문장 구성 토큰들의 n-gram을 추가로 도입하는 것. 우리는 여기서 bi-gram을 도입하자. 예를 들어 \"how are you ?\"의 bi-gram은 \"how are\", \"are you\" and \"you ?\"이다.\n",
        "\n",
        "따라서 여기서 generate_bigrams 함수를 도입하여 토큰화된 문장의 뒤에 bi-gram을 추가하자.\n"
      ],
      "metadata": {
        "id": "EqkJ8H2V0vtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive Mount"
      ],
      "metadata": {
        "id": "OczBRXqIXn6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo39NQ2JXqbX",
        "outputId": "d8526a64-f12a-4d43-96fc-a782d05c91cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd # 현재 경로 확인 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1tBoZtxaXq0H",
        "outputId": "0f105b7c-22b8-4a3e-9510-e7576d1ff561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/논문/sentimentP/dataset/Mecab-ko-for-Google-Colab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/논문/sentimentP/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvcNDbFoXzem",
        "outputId": "f0659069-889f-4bd8-acea-f3f31ed26fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/논문/sentimentP/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_hBVI0BXzlp",
        "outputId": "eb461bfc-5701-4a7f-8cec-1772678d771c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMecab-ko-for-Google-Colab\u001b[0m/  ratings_train.txt  train_data.csv\n",
            "ratings_test.txt            test_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 패키지와 랜덤시드 설정"
      ],
      "metadata": {
        "id": "Cbv1p9Ct3t8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchtext==0.10.1 \n",
        "!pip install torch==1.8.0 torchtext==0.9.0\n",
        "\"\"\"\n",
        "아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\n",
        "\n",
        "torchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\n",
        "pip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\n",
        "\n",
        "https://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "j5_jZkVj367x",
        "outputId": "27300e94-0158-43e3-93fc-8c10aaaaa45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.8/dist-packages (1.8.0)\n",
            "Requirement already satisfied: torchtext==0.9.0 in /usr/local/lib/python3.8/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\\n\\ntorchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\\npip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\\n\\nhttps://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_bigrams(x):\n",
        "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
        "    for n_gram in n_grams:\n",
        "        x.append(' '.join(n_gram))\n",
        "    return x"
      ],
      "metadata": {
        "id": "BpZxHLGbXBPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = ['너', '임마', '밥은', '먹고', '다니냐']\n",
        "n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
        "n_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq1pptzqXEZ9",
        "outputId": "5969bb42-0293-4260-aa2f-8856713098f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('너', '임마'), ('먹고', '다니냐'), ('밥은', '먹고'), ('임마', '밥은')}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_bigrams(['너', '임마', '밥은', '먹고', '다니냐'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4EGM4eEXGJm",
        "outputId": "7003eb04-da50-42c7-beba-17929d594e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['너', '임마', '밥은', '먹고', '다니냐', '밥은 먹고', '임마 밥은', '먹고 다니냐', '너 임마']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torchtext의 Field는 preprocessing 과정이 있어서 여기에 함수를 전달하면 토크나이징 후 적용된다. 여기에 generate_bigrams 함수를 넣기\n",
        "* 우리는 한글 데이터를 다루므로 토크나이저 또한 별도로 지정해야함\n",
        "* KoNLPy의 은전한닢 tokenizer를 이용\n",
        "* 또한 패딩을 추가한다.\n",
        "* 여기서는 RNN 안쓸 거기 때문에 packed padded seq.를 쓸 수 없어서 include_lengths=True 또한 넣을 필요가 없음"
      ],
      "metadata": {
        "id": "d4eUK_tQXLN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리\n",
        "> Filed 지정 / KoNLPy의 은전한닢(Mecab) tokenizer 이용"
      ],
      "metadata": {
        "id": "7J-BU7987OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 내 다운로드 https://wikidocs.net/94600\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVimlTus405w",
        "outputId": "dd94829e-6c55-404b-d17f-1957d4396cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/논문/sentimentP/dataset/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-01-29 16:52:09--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.2, 18.205.93.0, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNFWFGAGPL&Signature=ga9KZDAZMfa2c%2BU0YwhVlbQOBJI%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDPp1Wvq6v%2Fwr0cklkSK%2BASiIOTb6cO1BByzgc2UqhuWuCg%2FIQWnwMrS02JQh7iJ230BxPetcv9F9Hzp613i5LH%2Fq08D1pmAqgFYbNAmv4R78Agfzv7Trlm9efRz1rkr7c2%2BOmTWaEkJSd1%2BAtqcM8FNQNHhy3OvBIK8Vs74LKuLyTnaD07RcPpgKIYptMxh%2FOfRlJlLhtWpncQdt%2FnBY7MjmcMVLR%2Bo8yAikHyUO0TTZxzICShQufoCWwFerS2InQ%2BxUm%2FMKGLqjwfXI6KEousjangYyLTwussPgm5XcfvhZ3fu3s3GPsBuYwvdngy%2ByK%2FxPnj3MY8I5T9LmS%2BfeW76xsQ%3D%3D&Expires=1675012930 [following]\n",
            "--2023-01-29 16:52:10--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNFWFGAGPL&Signature=ga9KZDAZMfa2c%2BU0YwhVlbQOBJI%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDPp1Wvq6v%2Fwr0cklkSK%2BASiIOTb6cO1BByzgc2UqhuWuCg%2FIQWnwMrS02JQh7iJ230BxPetcv9F9Hzp613i5LH%2Fq08D1pmAqgFYbNAmv4R78Agfzv7Trlm9efRz1rkr7c2%2BOmTWaEkJSd1%2BAtqcM8FNQNHhy3OvBIK8Vs74LKuLyTnaD07RcPpgKIYptMxh%2FOfRlJlLhtWpncQdt%2FnBY7MjmcMVLR%2Bo8yAikHyUO0TTZxzICShQufoCWwFerS2InQ%2BxUm%2FMKGLqjwfXI6KEousjangYyLTwussPgm5XcfvhZ3fu3s3GPsBuYwvdngy%2ByK%2FxPnj3MY8I5T9LmS%2BfeW76xsQ%3D%3D&Expires=1675012930\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.235.89, 52.217.165.169, 54.231.232.97, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.235.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.1’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-01-29 16:52:10 (11.7 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.1’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-01-29 16:52:35--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.0, 18.205.93.1, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNH6DP3CLK&Signature=SZ0KiaBIL12HaYnbomK1b0lHfGo%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDN1ZmdHyHka0beCHKyK%2BAfHIM0j6IyCKEAniioH69LF3p5IlmocExf1tHW4oktZ1plqimuaeMLlBNqXkLYyMBI36sPSqf%2FC0dIYVoUAnerzRqcsjt9EsMkjxNyEyuk4SoUR2P1Q4WCkE7ufVDaq1dOjX1MGLPhb9jd0or81e4g8jA9zi6tlTajJt2lcz2TfSzLOYmoH31mYcuw0W1Qg4NSSjoLUF5w8%2Bsots1c1FusMTa3YJ3refccoZM%2FB0IhvaRDzssu9WHm27IVjL5Rso08jangYyLSb7DV20m0zFTBGZ7kpcCpU9dx9VieTHzTCU5eVoGfL4t2Od4mzq%2BHADbpkN2w%3D%3D&Expires=1675012955 [following]\n",
            "--2023-01-29 16:52:35--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNH6DP3CLK&Signature=SZ0KiaBIL12HaYnbomK1b0lHfGo%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDN1ZmdHyHka0beCHKyK%2BAfHIM0j6IyCKEAniioH69LF3p5IlmocExf1tHW4oktZ1plqimuaeMLlBNqXkLYyMBI36sPSqf%2FC0dIYVoUAnerzRqcsjt9EsMkjxNyEyuk4SoUR2P1Q4WCkE7ufVDaq1dOjX1MGLPhb9jd0or81e4g8jA9zi6tlTajJt2lcz2TfSzLOYmoH31mYcuw0W1Qg4NSSjoLUF5w8%2Bsots1c1FusMTa3YJ3refccoZM%2FB0IhvaRDzssu9WHm27IVjL5Rso08jangYyLSb7DV20m0zFTBGZ7kpcCpU9dx9VieTHzTCU5eVoGfL4t2Od4mzq%2BHADbpkN2w%3D%3D&Expires=1675012955\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.135.161, 52.216.131.75, 52.217.80.180, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.135.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  91.7MB/s    in 0.5s    \n",
            "\n",
            "2023-01-29 16:52:36 (91.7 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "KGx9Cp-0daAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.legacy import data # 추가\n",
        "\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "ZRYJx-XZdhop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = torchtext.legacy.data.Field(tokenize = mecab.morphs, preprocessing = generate_bigrams)\n",
        "LABEL = torchtext.legacy.data.LabelField(dtype = torch.float)"
      ],
      "metadata": {
        "id": "d_pchz0J3xxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__\n",
        "torchtext.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F9nWfROP6dCb",
        "outputId": "e11593d9-feed-40f6-dc73-22f53a2517cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.9.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리된 네이버 영화 평점 데이터를 불러오고 검증 데이터를 추가"
      ],
      "metadata": {
        "id": "Y5LgoodH5koB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fields = {'text': ('text', TEXT), 'label': ('label', LABEL)}\n",
        "# dictionary 형식; {csv 컬럼명 : (데이터 컬럼명, Field이름)}"
      ],
      "metadata": {
        "id": "piJA-nb56ttT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = data.TabularDataset.splits(\n",
        "    path = '.',\n",
        "    train = 'train_data.csv',\n",
        "    test = 'test_data.csv',\n",
        "    format = 'csv',\n",
        "    fields = fields\n",
        ")"
      ],
      "metadata": {
        "id": "zmCRdQD48RTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "metadata": {
        "id": "p50AxAKNYlwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 검증데이터 별도 생성"
      ],
      "metadata": {
        "id": "YmK9NEtt8-h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "metadata": {
        "id": "07qme4jX9CbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단어 벡터는 전처리된 단어 벡터를 받아보기\n",
        "> * 한글을 지원하는 fasttext.simple.300d 사용 <br>\n",
        "> * 사전훈련된 단어집에 없는 단어는 0으로 처리하는 걸 방지하기 위해 unk_init = otrch.Tensor.normal_옵션을 줌"
      ],
      "metadata": {
        "id": "UeQYq6Gek346"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 총 단어의 수 확인"
      ],
      "metadata": {
        "id": "sCiduXqL849A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size=MAX_VOCAB_SIZE,\n",
        "                 vectors = 'fasttext.simple.300d',\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "Qsk45f7_-MTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(TEXT.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6izlknClmYP",
        "outputId": "5e5ee607-c095-456b-c173-9c03254a3a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25002"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.itos[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuAs2bcVYxtJ",
        "outputId": "225d0385-239e-4205-87bf-3a41a70e5ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '.', '이', '는']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL.vocab.stoi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX-JUcdHln8p",
        "outputId": "9f754665-4826-4825-b6c1-51c95fb2ea6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None, {'0': 0, '1': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars(train_data.examples[15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oyBz15Rlryw",
        "outputId": "df616862-4565-459f-8999-005d1a385e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['보',\n",
              "  '고',\n",
              "  '나',\n",
              "  '서',\n",
              "  '도',\n",
              "  '참',\n",
              "  '찝찝',\n",
              "  '한',\n",
              "  '영화',\n",
              "  '.',\n",
              "  '..',\n",
              "  '영화 .',\n",
              "  '참 찝찝',\n",
              "  '. ..',\n",
              "  '고 나',\n",
              "  '서 도',\n",
              "  '보 고',\n",
              "  '나 서',\n",
              "  '찝찝 한',\n",
              "  '한 영화',\n",
              "  '도 참'],\n",
              " 'label': '0'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BuketIterator를 이용하여 데이터 생성자 만들기\n",
        "* 데이터 생성자를 만드는데, 길이에 따라 정렬하도록 sort_within_batch = True옵션을 넣어줄 것을 원 튜토리얼에서 요구하나\n",
        "* 한글 데이터에선 오류가 발생하여 sort_key=lambda x:len(x.text) 문장을 먼저 넣어줘야 오류없이 작동함"
      ],
      "metadata": {
        "id": "q2py_-SKaX8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    # sort_within_batch = True,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "D5ZmsBZiaccO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 패딩 제외 길이로 정렬된 (문장, 길이) 순의 데이터로 이루어져있음"
      ],
      "metadata": {
        "id": "rak9IFCrmxS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_iterator)).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWgr5g7cmqGo",
        "outputId": "b8d45cf3-70e6-40bf-f66e-6192ca6c4031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11944,  1203,     0,     3,   629,  2252,  1759,  1727,   129,   121,\n",
              "          1723,    97,    75, 11938,    31,    62,     3,   569,    86,   163,\n",
              "           611,  1615,     5,  3990,    75,     3, 10438,   113,   124,   269,\n",
              "            31,    15,  4384,  4384,   776,   220,    35,   321,     0,   262,\n",
              "           493,   170,     0,  2252,    67,  1368,   984,     0,   761,   109,\n",
              "           397,    71,     0,    47, 17821, 21723,   193,   912,    81,     0,\n",
              "          5038,   170,    82,    15],\n",
              "        [   69,     3,   617,     5,    36,    13,  2922,   241,   606,    11,\n",
              "            38,    67,   325,    33,    10,  6996,     5,   657,    62,   305,\n",
              "          1004,     3,   419,   122,   325,     5,    13,     3,    34,   872,\n",
              "            10,     4,  8207,  2709,     5,    18,   124,   121,   230,  3374,\n",
              "         22133,    84,     0,  3712,  1177,   525,    13,     0,    14,   491,\n",
              "           606,     6,   280,  1662,  8834,     0,    26,   103,   140,    19,\n",
              "           130,    13,    30,   201],\n",
              "        [ 3585, 15070, 11634,    15,    43,     0,    11,    11,   103,    84,\n",
              "            56,    85,    71,     0,  2884,  4734,   525,   125,   496,  8059,\n",
              "            26,   217,    11,   350,    71,     4,   121,  3634,    88,  4525,\n",
              "           717,   306,    96,     3,  1226,    39,   235,    24,   122,    44,\n",
              "             0,   199,    11,    13,  5313, 13308,    10,     3,  5268,     3,\n",
              "          1003,     2,    13,     2,     9,  3443,    35,   291,     5,   104,\n",
              "           197,     0,     7,   346],\n",
              "        [   56,  2906,    16,     4,    47,     8,   200,    37,    15,   210,\n",
              "          1125,    42,     9,    18,   275,  3821,   147,     8,    49,   161,\n",
              "           406,    14,   140,  1474,     9,  2053,    11,     3,  1045,    10,\n",
              "           154,  1596,   275,   568,  1226,   193,  1124,    19,   230,   582,\n",
              "          5119,    12,  4791, 10735,  1893,     0,   135,    97,    40,    52,\n",
              "            50,    92,   167,   253,    69,  1123,   262,   370,     4,    82,\n",
              "             9,   169,  1091,   699],\n",
              "        [    0,    58,     0,   419,    19,    19,     6,    11,   239,     9,\n",
              "            19,    10,    93,  3058,    11,   110,   272,     6,    47,  3914,\n",
              "            46,  5619,     6,    50,  3723,     3,  2734,    56,   221,    37,\n",
              "             4,    16,     0,   312,   321,  1901,   147,    38,     3,    12,\n",
              "            28,    49,  3827,    26,  5313,     4,    19,   653,   417,    62,\n",
              "             6,   123,    14,  9154,     4,   109,    53,    19,   196,    30,\n",
              "           230,    72,     3,  8140],\n",
              "        [   35,    41,     9,    11,    38,     0,    23,     4,     2,   588,\n",
              "           135,    28,    23,     4,  6014,   149,    46,     5,    80,    29,\n",
              "           391, 16946,     2,    12,    23,  5619,    53,     2,    31,   117,\n",
              "             2,     5, 16115,  2918,    47,   176,   510,     0,   152,  6096,\n",
              "            87,  3296,    87,     0,     5, 13281,    38,    90,     4,  1721,\n",
              "             2,    15,    93, 22881,     2,     0,     6,    38,     3,    12,\n",
              "           122,   530,   996,  4729],\n",
              "        [ 5467,   174,   161,  3590,     6,  1969,   261,     5,     2,   933,\n",
              "            41,     6,   261,     0,     2,   163,     0,    11,    74,  3411,\n",
              "           134,     2,    17,  3990,    62,     6,    80,    92,    62,     5,\n",
              "            17,  2481,     0,    24,    80,     2,     6,   336,    94,     5,\n",
              "           246,     6,     2,     5,     2,     2,     6,    56,     5,    19,\n",
              "            92,  2226,   437,     2,    92,   239,     2,     6,     6,     5,\n",
              "           164,   751,     6,     6],\n",
              "        [    0,  7230,     0, 24012,   734,     0,   313,    60,    21,     0,\n",
              "          1945,   165,  1512,     0,     0,     0,     0,  4848,   701, 10101,\n",
              "          4651,  4744,  3475,  1927,  1512,  8850,     0,   924,  9999, 10474,\n",
              "          5767,   126,     0, 18981,     0,   689,     0, 19290, 17752,     0,\n",
              "             0,  4663,   166,     0,     0,     0,   610, 13959,    60,   775,\n",
              "         16953,  7055,  2193,     0,   430,     0,   303,   401,    89,     0,\n",
              "          6287,   744, 14765,     0],\n",
              "        [    0,  4108,     0,   448,   403, 14399,   318,  9502,  2935,  6596,\n",
              "          3824,   486,  2390,  7674,     0,  9600,     0,     0,  1488,     0,\n",
              "         11263,     0,    25,     0, 15299,   141, 15192,   195,     0,   330,\n",
              "            25,   365,     0,     0,  8978, 14403,  1660,   250,   673,     0,\n",
              "             0,  2685,     0,     0,     0,     0,   403,     0,   644,     0,\n",
              "             0,   791,     0,     0,   577,  7667,  3330,  1714,  2374,   183,\n",
              "          6410,     0, 20833,     0],\n",
              "        [    0,   865,     0,     0,   250,     0,  3402,   835,     0,  3921,\n",
              "          1616,   194,  1230,     0,     0,     0,     0,   119,   682,     0,\n",
              "           794, 21864, 10217, 24261, 18780,     0,     0, 19796,  6059,     0,\n",
              "           577, 12430,     0,     0,     0,     0,  9062,     0,     0,     0,\n",
              "             0, 20992,     0,     0,     0,     0,   250,     0,     0,     0,\n",
              "            20,  4339,     0,     0,     0,     0,    20,   403,  1207,     0,\n",
              "          5262, 23594, 12770,  7429],\n",
              "        [    0,  6511,  2139,   102,   276,     0,  1812,  2031,  1784,   733,\n",
              "          5466,  1529,   185,     0,     0,     0,   102,   273, 11132,     0,\n",
              "             0, 14339,  2015,     0,   185,   102,   852,   105, 12731,  5078,\n",
              "             0,     0,     0,     0,   682,  3366,  1310, 13530,  5262,     0,\n",
              "          3525,     0,     0,  7959,  5172,     0,  4382,  1571,     0,  2647,\n",
              "           105,    20,   879, 22131,   105,     0,  2616,   250,   141,   144,\n",
              "          1292,     0,   781,   503],\n",
              "        [    0,     0,     0,  1191,   268,   127,  4409,   845,  2068,   852,\n",
              "             0,     0,   287,     0,   725,     0,     0,     0,  1348,  5407,\n",
              "          3675,     0,    20,     0,  6581, 10032,  1960,   556,     0,     0,\n",
              "           407,   145,     0,     0,     0,  5698, 10091,     0,  1014, 13347,\n",
              "             0, 11336,     0,     0,    66, 14213,  1734,     0,  4279,     0,\n",
              "           338,   105, 17584,  2511,   841,     0,  8477,     0,   497,   860,\n",
              "          2035,     0, 15090,  2400],\n",
              "        [    0,     0,     0,   126,  8281,     0,   287,   586,  3814,     0,\n",
              "          1031,  2625,   803,     0,     0,  1317,  1518,   148, 23807,  3693,\n",
              "             0,     0,  1191,   173,   803, 22808,     0,     0,  2996,  5277,\n",
              "           725,  5744,     0,     0,     0,     0, 20350,  7138,   895,  2386,\n",
              "          3519, 11700,     0,     0,     0,     0,  5480,   883,  6468,  3887,\n",
              "          5330,  9776,   850,  9508,     0,     0,  5711,  2603,  1703, 15090,\n",
              "           755,     0,     0,  9831]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.itos[2533], TEXT.vocab.itos[54], TEXT.vocab.itos[2647]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHw27-gyZZ4m",
        "outputId": "3c4c1b16-3db9-4ffd-d1b0-9266bc2d7900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('이 높', '에서', '가볍 게')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.itos[14207], TEXT.vocab.itos[14207], TEXT.vocab.itos[556]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5ueyTR7ZbJO",
        "outputId": "ec1d4f83-0857-4bd4-dcb5-5a686441b1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('약속', '약속', '감독 이')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 생성\n",
        "*  입력 문장을 임베딩 시킨 후 평균을 취한 다음 행렬곱을 취하는 모델을 사용한다. RNN을 사용하지 않기 때문에 파라미터 수가 훨씬 줄어들었다.\n",
        "* 평균은 다음과 같은 방식으로 취하며 nn.functional.avg_pool2d 를 사용한다. \n",
        "* 이 함수는 2차원 튜플을 인수로 받으며, 입력 데이터의 마지막 2개 차원을 이용하여 평균을 산출한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "F5dd6y9kmu5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "wnXV66_8n0LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사이즈 계산을 위한 함수 사용"
      ],
      "metadata": {
        "id": "hx5ckSZvZwwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_shape(name, data):\n",
        "    print(f'{name} has shape {data.shape}')"
      ],
      "metadata": {
        "id": "FUthbp0Xn75v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.functional.avg_pool2d?"
      ],
      "metadata": {
        "id": "wvHt122DZ0is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = torch.rand(2,5,10)\n",
        "txt.shape, F.avg_pool2d(txt, (5,1)).shape\n",
        "# (5 x 1) 크기의 필터를 옮겨가며 평균을 구한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyvZkHLIZ1t9",
        "outputId": "c36406d4-81b4-4e0f-f2ec-e7ee674434e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 5, 10]), torch.Size([2, 1, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = torch.tensor(\n",
        "    [[[1,2,3,4],[4,5,6,7]]], dtype=torch.float\n",
        ")\n",
        "print(txt.shape,\"\\n\", txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDOZ9f7yZ3TC",
        "outputId": "9755898b-26a3-4966-9678-5deb4b63fd47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 4]) \n",
            " tensor([[[1., 2., 3., 4.],\n",
            "         [4., 5., 6., 7.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.avg_pool2d(txt, (2,1)).shape, F.avg_pool2d(txt, (2,1))\n",
        "# (2 x 1) 필터로 평균을 취함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6d0-K5OZ4v0",
        "outputId": "21ee0dac-814d-40c4-ef34-e8c552039437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 4]), tensor([[[2.5000, 3.5000, 4.5000, 5.5000]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.avg_pool2d(txt, (2,2)).shape, F.avg_pool2d(txt, (2,2))\n",
        "# (2 x 2) 필터로 평균을 취함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFZOyS9zZ6E2",
        "outputId": "9355c86e-e1c2-4201-ce72-d76a63aa07ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 2]), tensor([[[3., 5.]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FastText 모델을 구현하자. 다만 여기서 주의할 점!\n",
        "\n",
        "* RNN은 [sent_len, batch_size, embedding_dim] 크기의 텐서를 입력으로 받음\n",
        "* CNN은 [batch_size, sent_len, embedding_dim] 크기의 텐서를 입력으로 받음"
      ],
      "metadata": {
        "id": "99z9yM1OaBYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FastText(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        # text = [sent_len, batch_size]\n",
        "        #print_shape('text', text)\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        #print_shape('embedded', embedded)\n",
        "        # embedded = [sent_len, batch_size, embedding_dim]\n",
        "        \n",
        "        # CNN은 [batch_size, sent_len, embedding_dim] 를 입력으로 받음\n",
        "        # 따라서 permute 취해줘야 함\n",
        "        embedded = embedded.permute(1,0,2)\n",
        "        #print_shape('embedded', embedded)\n",
        "        # embedded = [batch_size, sent_len, embedding_dim]\n",
        "        \n",
        "        pooled = F.avg_pool2d(embedded, (embedded.shape[1],1)).squeeze(1)\n",
        "        #print_shape('pooled', pooled)\n",
        "        # pooled = [batch_size, embedding_dim]\n",
        "        \n",
        "        res = self.fc(pooled)\n",
        "        #print_shape('res', res)\n",
        "        # res = [batch_size, output_dim]\n",
        "        return res"
      ],
      "metadata": {
        "id": "eeSkj--daG-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사이즈 계산 확인"
      ],
      "metadata": {
        "id": "ggI1qO-wafpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#inp = next(iter(train_iterator))\n",
        "#model(inp.text)"
      ],
      "metadata": {
        "id": "eQbsXEa5ai_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 하이퍼파라미터를 설정하고 인스턴스화"
      ],
      "metadata": {
        "id": "MnpVHsOzaj0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "OUTPUT_DIM = 1\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
      ],
      "metadata": {
        "id": "Ppc3mJTmalnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파라미터 수는?\n",
        "* 지난 모델에 비해 약 3/4 으로 감소했다는 것을 알 수 있다."
      ],
      "metadata": {
        "id": "0B_40lxOanoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'모델의 파라미터 수는 {count_parameters(model):,} 개 입니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTVfjKwgapcb",
        "outputId": "e7fe2e7f-e741-453c-c7b4-3fb38fe94d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 파라미터 수는 7,500,901 개 입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 훈련된 단어 벡터를 덮어 씌우고 먼저 텐서 차원을 비교해보기 "
      ],
      "metadata": {
        "id": "jtueJMW-avXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_weight = TEXT.vocab.vectors\n",
        "print(pretrained_weight.shape, model.embedding.weight.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LLVequ0ay8b",
        "outputId": "13c871be-f0fe-4141-ee8c-1d226ee06c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25002, 300]) torch.Size([25002, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data.copy_(pretrained_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShDQDWQTa2VP",
        "outputId": "d8c90012-c2cc-4b57-8797-a0c24d05cf10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.4447,  0.8402, -0.8668],\n",
              "        [ 0.1032, -1.6268,  0.5729,  ...,  0.3180, -0.1626, -0.0417],\n",
              "        [ 0.0569, -0.0520,  0.2733,  ..., -0.0695, -0.1606, -0.0989],\n",
              "        ...,\n",
              "        [ 0.2542,  1.2173,  1.8023,  ..., -0.9746,  0.1054, -1.7293],\n",
              "        [-0.1084, -0.5668,  0.1102,  ..., -0.5685,  1.6376,  0.2508],\n",
              "        [-0.3535,  1.0225, -1.7970,  ...,  0.0683,  0.3403,  1.5236]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "sZzwtai_a40o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 훈련"
      ],
      "metadata": {
        "id": "id_KKFCTa58T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "F_YIBliLa7rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "sNhpTviSa9fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds==y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "z7TxMM-5a-Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 정의 \n",
        "*  model.train() 사용"
      ],
      "metadata": {
        "id": "ArRK7ioVa_VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch.text).squeeze(1) # output_dim = 1\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "-ZlXfhMIbDpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "5fsKUG_TbEei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "Sa03a_ZwbGoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련해보기"
      ],
      "metadata": {
        "id": "AWlTy1CKbJW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSd2UWHubIH6",
        "outputId": "9b30697e-e6e8-456d-a8e9-5a6d3fff1336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 17s\n",
            "\tTrain Loss: 0.471 | Train Acc: 79.25%\n",
            "\t Val. Loss: 0.381 |  Val. Acc: 84.17%\n",
            "Epoch: 02 | Epoch Time: 1m 14s\n",
            "\tTrain Loss: 0.329 | Train Acc: 86.87%\n",
            "\t Val. Loss: 0.351 |  Val. Acc: 85.68%\n",
            "Epoch: 03 | Epoch Time: 1m 13s\n",
            "\tTrain Loss: 0.281 | Train Acc: 89.05%\n",
            "\t Val. Loss: 0.351 |  Val. Acc: 85.72%\n",
            "Epoch: 04 | Epoch Time: 1m 13s\n",
            "\tTrain Loss: 0.251 | Train Acc: 90.38%\n",
            "\t Val. Loss: 0.359 |  Val. Acc: 85.72%\n",
            "Epoch: 05 | Epoch Time: 1m 12s\n",
            "\tTrain Loss: 0.228 | Train Acc: 91.27%\n",
            "\t Val. Loss: 0.374 |  Val. Acc: 85.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트셋 돌려보기"
      ],
      "metadata": {
        "id": "ZjZwnYfObMKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcrMsBxabNNl",
        "outputId": "7ffff0b9-16f3-4467-fdf7-92679120282f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.357 | Test Acc: 85.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+6:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GGDE0tqbPQX",
        "outputId": "6b47e1b2-46db-41a8-bdbc-8a33ef927196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 06 | Epoch Time: 1m 13s\n",
            "\tTrain Loss: 0.248 | Train Acc: 90.46%\n",
            "\t Val. Loss: 0.361 |  Val. Acc: 85.66%\n",
            "Epoch: 07 | Epoch Time: 1m 14s\n",
            "\tTrain Loss: 0.228 | Train Acc: 91.36%\n",
            "\t Val. Loss: 0.374 |  Val. Acc: 85.46%\n",
            "Epoch: 08 | Epoch Time: 1m 12s\n",
            "\tTrain Loss: 0.211 | Train Acc: 92.01%\n",
            "\t Val. Loss: 0.392 |  Val. Acc: 85.28%\n",
            "Epoch: 09 | Epoch Time: 2m 6s\n",
            "\tTrain Loss: 0.197 | Train Acc: 92.49%\n",
            "\t Val. Loss: 0.415 |  Val. Acc: 84.95%\n",
            "Epoch: 10 | Epoch Time: 1m 30s\n",
            "\tTrain Loss: 0.186 | Train Acc: 92.96%\n",
            "\t Val. Loss: 0.437 |  Val. Acc: 84.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 오버피팅 발생 확인"
      ],
      "metadata": {
        "id": "_s_cS1dTbQkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNlQnX7JbVVb",
        "outputId": "0c1f2a0c-fad1-4f5f-e8e9-39a07323d035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.357 | Test Acc: 85.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 성능은 이전 모델과 거의 비슷하지만 훈련 시간이 대폭 감소!"
      ],
      "metadata": {
        "id": "30fVn4XdbTy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사용자 데이터 사용\n",
        "\n",
        "> 영화 평가 데이터 직접 넣어보자.\n",
        "> 다음 기능을 하는 predict_sentiment 함수를 만들자.\n",
        "\n",
        "* sets the model to evaluation mode\n",
        "* tokenizes the sentence, i.e. splits it from a raw string into a list of tokens\n",
        "* indexes the tokens by converting them into their integer representation from our vocabulary\n",
        "* gets the length of our sequence\n",
        "* converts the indexes, which are a Python list into a PyTorch tensor\n",
        "* add a batch dimension by unsqueezeing\n",
        "* converts the length into a tensor\n",
        "* squashes the output prediction from a real number between 0 and 1 with the * sigmoid function\n",
        "* converts the tensor holding a single value into an integer with the item() method"
      ],
      "metadata": {
        "id": "xSVvnBiybaXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "Yh_SgnbRbdRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = generate_bigrams([tok for tok in mecab.morphs(sentence)])\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1) # 배치 \n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction.item()"
      ],
      "metadata": {
        "id": "oE5SQpeQbuNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(model, \"이 영화 진짜 재밌었다!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7WR7rP6bv0B",
        "outputId": "3c3ef72e-008e-46a6-baba-42584b8d2853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9987062215805054"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(model, \"영화관에서 이걸 본 내가 바보다. 내 돈 돌려줘!!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dlqPw5Ibwhf",
        "outputId": "cb6a669f-ee80-4eb6-91ae-3397cf7d60da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002133105881512165"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    }
  ]
}
