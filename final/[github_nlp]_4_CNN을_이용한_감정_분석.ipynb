{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#이 튜토리얼에서는 Convolutional Neural Networks for Sentence Classification 논문에서 제시된 CNN 기반 모델을 이용해서 감정 분석을 해보자. 일반적으로 CNN은 비전 관련 데이터를 처리할 때 사용되지만, 위 논문에서는 [1 x 2] 크기의 필터를 이용하여 bi-gram과 유사한 효과를 얻어내었다.\n"
      ],
      "metadata": {
        "id": "EqkJ8H2V0vtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive Mount"
      ],
      "metadata": {
        "id": "OczBRXqIXn6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo39NQ2JXqbX",
        "outputId": "adb66769-7209-44a4-98ee-485b677dd8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd # 현재 경로 확인 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1tBoZtxaXq0H",
        "outputId": "1a7b9904-fbf1-4b17-dfe4-20ddc3f9ac15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/논문/sentimentP/dataset/Mecab-ko-for-Google-Colab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/논문/sentimentP/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvcNDbFoXzem",
        "outputId": "40efeca8-8cff-4f86-bfb0-28efa146b623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/논문/sentimentP/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_hBVI0BXzlp",
        "outputId": "55e4d9af-c0a0-485a-9f6c-fdc0ad9c4d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMecab-ko-for-Google-Colab\u001b[0m/  ratings_train.txt  train_data.csv\n",
            "ratings_test.txt            test_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 패키지와 랜덤시드 설정"
      ],
      "metadata": {
        "id": "Cbv1p9Ct3t8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchtext==0.10.1 \n",
        "!pip install torch==1.8.0 torchtext==0.9.0\n",
        "\"\"\"\n",
        "아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\n",
        "\n",
        "torchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\n",
        "pip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\n",
        "\n",
        "https://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "j5_jZkVj367x",
        "outputId": "781e069a-5dc6-4c1f-cc51-be676ce4df73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.8/dist-packages (1.8.0)\n",
            "Requirement already satisfied: torchtext==0.9.0 in /usr/local/lib/python3.8/dist-packages (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2.10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\\n\\ntorchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\\npip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\\n\\nhttps://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리\n",
        "* 이 모델은 앞서 설명한 것처럼 CNN의 필터를 이용하기 때문에 FastText처럼 bi-gram 생성 함수를 이용할 필요가 없다. 우리는 한글 데이터를 다루므로 토크나이저 또한 별도로 지정해야한다. \n",
        "* 여기서는 KoNLPy의 은전한닢 tokenizer를 이용한다.\n",
        "* CNN 모델은 지난 번에 설명한 것처럼 배치 사이즈를 첫번째 차원으로 받기 때문에 batch_first = True 옵션을 주면 된다."
      ],
      "metadata": {
        "id": "7J-BU7987OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 내 다운로드 https://wikidocs.net/94600\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVimlTus405w",
        "outputId": "ac62a873-718c-407c-ba1a-88ad8a434ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/논문/sentimentP/dataset/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-01-29 17:22:46--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLW3EEB77&Signature=1lK075Xu%2FD1lJz3QCLf4nkU6Kkw%3D&x-amz-security-token=FwoGZXIvYXdzEBMaDLpW49H4y9Yk8qd5NSK%2BAVE8wQUWMYasDDnJSZiGxGkbomoik5oE5hTFA20C6qSWGAvyx6Jb3y%2FqYqI7B5QdDovOLoKHjdOMcRJIEBD%2FpVbzAkUid7o7MBNN7Yt5Vp0Xo8uTa%2B5h2gnkpUD%2FIdfiPezoofvhztnhuHCMlJSEI9vj5jN5jTJpAFgdHt2gnKhwVcu%2BMC5gkhYlnRN7rUd5tCZPrNyv7H%2FKmpijzIG47QbQBhZzTsYrUwEYwywIyfMEnyvc2nIafu2gXuhtMRcoh9HangYyLe22IL%2BdmqZZQwqcr4lKPWy5v9onOY3m15X%2F0s4ocAyrSne%2Ffw6Ok4j%2FXwsA%2FQ%3D%3D&Expires=1675014031 [following]\n",
            "--2023-01-29 17:22:47--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLW3EEB77&Signature=1lK075Xu%2FD1lJz3QCLf4nkU6Kkw%3D&x-amz-security-token=FwoGZXIvYXdzEBMaDLpW49H4y9Yk8qd5NSK%2BAVE8wQUWMYasDDnJSZiGxGkbomoik5oE5hTFA20C6qSWGAvyx6Jb3y%2FqYqI7B5QdDovOLoKHjdOMcRJIEBD%2FpVbzAkUid7o7MBNN7Yt5Vp0Xo8uTa%2B5h2gnkpUD%2FIdfiPezoofvhztnhuHCMlJSEI9vj5jN5jTJpAFgdHt2gnKhwVcu%2BMC5gkhYlnRN7rUd5tCZPrNyv7H%2FKmpijzIG47QbQBhZzTsYrUwEYwywIyfMEnyvc2nIafu2gXuhtMRcoh9HangYyLe22IL%2BdmqZZQwqcr4lKPWy5v9onOY3m15X%2F0s4ocAyrSne%2Ffw6Ok4j%2FXwsA%2FQ%3D%3D&Expires=1675014031\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.135.161, 52.217.165.121, 52.217.83.212, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.135.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.1’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.75MB/s    in 0.4s    \n",
            "\n",
            "2023-01-29 17:22:47 (3.75 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.1’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-01-29 17:23:13--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNMKXXVYXH&Signature=uyQ4U0AVIIK7%2FDUJ23LobtiyBYs%3D&x-amz-security-token=FwoGZXIvYXdzEBMaDF7qck66LhSmn12%2FtyK%2BARSB91UI6a0eC79sTHNJzAq0Wd2%2Brua9TFoBJETDE5Qi%2FBn52yj7AJ%2F2ZrV%2BO9j8KVXT1TdYt2IwSXApWC4F4VCERffUyXyOGYh%2Fhu9M5EHpXB4Ll1ebkhEMaLfheTVxy0pwoBMzKG9u1qf8n5E25JLcFU4skXEiCxshrnfaZ4HlQWCwrldduoXswuGhTpk509ztFS%2BTJn%2FxyI6VeHhZOd%2BQS%2F7lm7CA4a4gogl19Dv4NYL5TRlrdmBzZqoEqLwo2NHangYyLYurkq3szhnNcpL97t%2FxEc3C6if5elV2TIuenZUxMp6Z1WtIar5VLQqUSyS6hQ%3D%3D&Expires=1675014112 [following]\n",
            "--2023-01-29 17:23:14--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNMKXXVYXH&Signature=uyQ4U0AVIIK7%2FDUJ23LobtiyBYs%3D&x-amz-security-token=FwoGZXIvYXdzEBMaDF7qck66LhSmn12%2FtyK%2BARSB91UI6a0eC79sTHNJzAq0Wd2%2Brua9TFoBJETDE5Qi%2FBn52yj7AJ%2F2ZrV%2BO9j8KVXT1TdYt2IwSXApWC4F4VCERffUyXyOGYh%2Fhu9M5EHpXB4Ll1ebkhEMaLfheTVxy0pwoBMzKG9u1qf8n5E25JLcFU4skXEiCxshrnfaZ4HlQWCwrldduoXswuGhTpk509ztFS%2BTJn%2FxyI6VeHhZOd%2BQS%2F7lm7CA4a4gogl19Dv4NYL5TRlrdmBzZqoEqLwo2NHangYyLYurkq3szhnNcpL97t%2FxEc3C6if5elV2TIuenZUxMp6Z1WtIar5VLQqUSyS6hQ%3D%3D&Expires=1675014112\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.192.41, 52.216.142.148, 54.231.232.145, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.192.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  27.8MB/s    in 1.7s    \n",
            "\n",
            "2023-01-29 17:23:16 (27.8 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "KGx9Cp-0daAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.legacy import data # 추가\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "SEED = 1027\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "ZRYJx-XZdhop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문장의 길이가 필터 사이즈보다 작으면 에러가 나므로 다음과 같이 토크나이저를 수정"
      ],
      "metadata": {
        "id": "6rV2Xze9hp3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILTER_SIZES = [3,4,5]\n",
        "def tokenizer(text):\n",
        "    token = [t for t in mecab.morphs(text)]\n",
        "    if len(token) < max(FILTER_SIZES):\n",
        "        for i in range(0, max(FILTER_SIZES) - len(token)):\n",
        "            token.append('<PAD>')\n",
        "    return token"
      ],
      "metadata": {
        "id": "PIeKRnfBhp9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(tokenize = tokenizer, batch_first = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "metadata": {
        "id": "qLVdi_KBhuGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fields = {'text': ('text',TEXT), 'label': ('label',LABEL)}\n",
        "# dictionary 형식은 {csv컬럼명 : (데이터 컬럼명, Field이름)}"
      ],
      "metadata": {
        "id": "7e0gGPjLhqAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "                            path = '.',\n",
        "                            train = 'train_data.csv',\n",
        "                            test = 'test_data.csv',\n",
        "                            format = 'csv',\n",
        "                            fields = fields,  \n",
        ")\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "metadata": {
        "id": "StbCmlaHhqFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단어 벡터 처리\n",
        "* 다음으로 단어 벡터는 전처리된 단어 벡터를 받자. 원 튜토리얼에선 glove.100d를 쓰지만 이건 한글을 지원하지 않으므로, 여기선 한글을 지원하는 fasttext.simple.300d 를 사용하겠다. \n",
        "* 그리고 사전훈련된 단어집에 없는 단어는 0으로 처리하는 걸 방지하기 위해 unk_init = torch.Tensor.normal_ 옵션을 준다."
      ],
      "metadata": {
        "id": "6BG9uEO0hqJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                max_size = MAX_VOCAB_SIZE,\n",
        "                vectors = 'fasttext.simple.300d',\n",
        "                unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "lc09ahAehzgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 생성자 만들기\n",
        "* 한글 데이터에선 오류가 발생해서 아래와 같이 sort_key = lambda x: len(x.text) 문장을 먼저 넣어줘야 오류없이 작동함"
      ],
      "metadata": {
        "id": "5XeLNQezhzjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "WKQVWfp2hqNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 생성\n",
        "* 입력 문장을 임베딩 시킨 후 2차원 CNN을 다음과 같이 적용\n",
        "* 필터 사이즈는 [n x emb_dim]\n",
        "* 이렇게 얻어진 벡터에 맥스 풀링(F.max_pool1d)을 적용한 후 ReLU 액티베이션을 적용한다.\n",
        "* 다양한 사이즈의 필터를 적용하여 얻어진 벡터를 concatenate한 후 드랍아웃을 적용하고 마지막으로 Linear 층에 통과 시켜 output 을 산출한다."
      ],
      "metadata": {
        "id": "2o4mKOyMhqRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "MDMS8zznhqUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 여러개의 CNN 레이어를 리스트 형태로 생성하기 위해 nn.ModuleList을 이용"
      ],
      "metadata": {
        "id": "eOmOK9ZshqX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사이즈 계산 함수 사용"
      ],
      "metadata": {
        "id": "3qWUrIPqiR3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_shape(name, data):\n",
        "    print(f'{name} has shape {data.shape}')"
      ],
      "metadata": {
        "id": "VFHLLx_siR8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(in_channels=1,\n",
        "                                             out_channels=n_filters,\n",
        "                                             kernel_size=(fs, embedding_dim))\n",
        "                                   for fs in filter_sizes])\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        #print_shape('text', text)\n",
        "        # text = [batch_size, sent_len]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        #print_shape('embedded', embedded)\n",
        "        # embedded = [batch_size, sent_len, emb_dim]\n",
        "        \n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        #print_shape('embedded', embedded)\n",
        "        # embedded = [batch_size, 1, sent_len, emb_dim]\n",
        "        \n",
        "        #print_shape('self.convs[0](embedded)', self.convs[0](embedded))\n",
        "        # self.convs[0](embedded) = [batch_size, n_filters, sent_len-filter_sizes[n]+1, 1 ]\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        \n",
        "        #print_shape('F.max_pool1d(conved[0], conved[0].shape[2])', F.max_pool1d(conved[0], conved[0].shape[2]))\n",
        "        # F.max_pool1d(conved[0], conved[0].shape[2]) = [batch_size, n_filters, 1]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "        #print_shape('cat', cat)\n",
        "        # cat = [batch_size, n_filters * len(filter_size)]\n",
        "        \n",
        "        res = self.fc(cat)\n",
        "        #print_shape('res', res)\n",
        "        # res = [batch_size, output_dim]\n",
        "        \n",
        "        return self.fc(cat)"
      ],
      "metadata": {
        "id": "D8q2PwcliSBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3,4,5]\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "metadata": {
        "id": "DDidQxfAiSFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 벡터 사이즈 체크"
      ],
      "metadata": {
        "id": "gUQf4DFmigMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "EgBx9zXTiSJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파라미터 개수는?"
      ],
      "metadata": {
        "id": "F8lfvww2iSON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'모델의 파라미터 수는 {count_parameters(model):,} 개 입니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_Key0O7iSSt",
        "outputId": "9e2391ba-51d3-4b4c-8c7d-0e981e7efccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 파라미터 수는 7,861,201 개 입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 훈련된 단어 벡터 불러오기"
      ],
      "metadata": {
        "id": "obli0seciSWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_weight = TEXT.vocab.vectors\n",
        "print(pretrained_weight.shape, model.embedding.weight.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAn1kHy4iSd9",
        "outputId": "d9fa53a7-f030-48ec-bf8f-1ea6c302407f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25002, 300]) torch.Size([25002, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data.copy_(pretrained_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8Gns4eSiShF",
        "outputId": "52e717a0-f65b-4a30-a7f2-fd48bb2a65da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1297e-01,  1.2156e+00,  6.8516e-01,  ..., -5.2034e-01,\n",
              "         -1.6626e-01, -8.4676e-04],\n",
              "        [ 9.0628e-01,  3.6853e-01, -6.4057e-01,  ...,  7.0754e-01,\n",
              "          6.3230e-01,  3.6939e-01],\n",
              "        [ 5.6857e-02, -5.1956e-02,  2.7326e-01,  ..., -6.9453e-02,\n",
              "         -1.6064e-01, -9.8923e-02],\n",
              "        ...,\n",
              "        [ 1.6462e-01,  3.1504e-01, -2.1961e-01,  ...,  1.2704e+00,\n",
              "          3.3490e-02,  6.4178e-01],\n",
              "        [ 9.2339e-01,  6.3520e-01, -8.0703e-01,  ...,  4.7187e-02,\n",
              "          9.4318e-01,  1.3437e+00],\n",
              "        [-3.4884e-01,  1.5506e+00, -3.0697e-01,  ..., -9.4593e-01,\n",
              "          5.8037e-01,  7.7458e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "CUdBNnwxiqvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 훈련"
      ],
      "metadata": {
        "id": "__fgwfGgiq0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "BDRkLo5riq5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "dNNCSBGkiq9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds==y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "c3y6D2UNirAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 함수 정의 \n",
        "*  여기선 드랍아웃 안쓰지만 model.train() 사용"
      ],
      "metadata": {
        "id": "-kZgbCs6i4K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch.text).squeeze(1) # output_dim = 1\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "X5vHRuYdirDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "04aHEzXLiyva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 얼마나 훈련 걸리는지 체크하는 함수"
      ],
      "metadata": {
        "id": "5KYglM8Ji004"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "idg9FGW-i0PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련시켜보기"
      ],
      "metadata": {
        "id": "0iGDqr8EhqbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNfwYgk1hqlm",
        "outputId": "c3b72b7e-b889-4eef-866d-580a1fc2749b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 5m 10s\n",
            "\tTrain Loss: 0.449 | Train Acc: 78.49%\n",
            "\t Val. Loss: 0.361 |  Val. Acc: 84.20%\n",
            "Epoch: 02 | Epoch Time: 5m 20s\n",
            "\tTrain Loss: 0.338 | Train Acc: 85.50%\n",
            "\t Val. Loss: 0.343 |  Val. Acc: 85.13%\n",
            "Epoch: 03 | Epoch Time: 5m 20s\n",
            "\tTrain Loss: 0.285 | Train Acc: 88.30%\n",
            "\t Val. Loss: 0.336 |  Val. Acc: 85.67%\n",
            "Epoch: 04 | Epoch Time: 5m 19s\n",
            "\tTrain Loss: 0.243 | Train Acc: 90.30%\n",
            "\t Val. Loss: 0.346 |  Val. Acc: 85.93%\n",
            "Epoch: 05 | Epoch Time: 5m 22s\n",
            "\tTrain Loss: 0.205 | Train Acc: 91.90%\n",
            "\t Val. Loss: 0.398 |  Val. Acc: 85.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트셋에 올려보기"
      ],
      "metadata": {
        "id": "PBtKEdtAjAMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut4-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0_je2hZjASb",
        "outputId": "ed570b24-d2ff-4ad9-9103-65632a113a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.340 | Test Acc: 85.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "더 훈련시키기"
      ],
      "metadata": {
        "id": "2MR55hWHjAWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+6:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fECNos5bjD58",
        "outputId": "a13b35cc-db17-4696-a6e8-1fbf128259da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 06 | Epoch Time: 5m 22s\n",
            "\tTrain Loss: 0.244 | Train Acc: 90.30%\n",
            "\t Val. Loss: 0.351 |  Val. Acc: 85.80%\n",
            "Epoch: 07 | Epoch Time: 5m 20s\n",
            "\tTrain Loss: 0.207 | Train Acc: 91.97%\n",
            "\t Val. Loss: 0.375 |  Val. Acc: 85.65%\n",
            "Epoch: 08 | Epoch Time: 5m 21s\n",
            "\tTrain Loss: 0.173 | Train Acc: 93.32%\n",
            "\t Val. Loss: 0.418 |  Val. Acc: 85.61%\n",
            "Epoch: 09 | Epoch Time: 5m 22s\n",
            "\tTrain Loss: 0.147 | Train Acc: 94.45%\n",
            "\t Val. Loss: 0.471 |  Val. Acc: 85.29%\n",
            "Epoch: 10 | Epoch Time: 5m 24s\n",
            "\tTrain Loss: 0.129 | Train Acc: 95.18%\n",
            "\t Val. Loss: 0.515 |  Val. Acc: 85.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 오버피팅 발생"
      ],
      "metadata": {
        "id": "_IkKMcDCjAa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut4-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-pQupTAjAep",
        "outputId": "4304fe59-950a-4622-f66a-570cec3cb25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.340 | Test Acc: 85.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 성능은 이전 모델과 거의 비슷. 훈련시간은 대폭 감소"
      ],
      "metadata": {
        "id": "Ks3zHpZBjJ9Z"
      }
    }
  ]
}