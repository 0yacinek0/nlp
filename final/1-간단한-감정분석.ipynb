{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EqkJ8H2V0vtm"
      ],
      "authorship_tag": "ABX9TyMdSnqnwWxJJqo3hgTHqFPx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0yacinek0/nlp/blob/practice/final/1-%EA%B0%84%EB%8B%A8%ED%95%9C-%EA%B0%90%EC%A0%95%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN 모델 이용하여 문장을 순차적으로 입력한 후 최종 hidden vector를 이용하여 문장이 긍정적인지 혹은 부정적인지 판단함\n"
      ],
      "metadata": {
        "id": "EqkJ8H2V0vtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 패키지와 랜덤시드 설정"
      ],
      "metadata": {
        "id": "Cbv1p9Ct3t8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchtext==0.10.1 \n",
        "!pip install torch==1.8.0 torchtext==0.9.0\n",
        "\"\"\"\n",
        "아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\n",
        "\n",
        "torchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\n",
        "pip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\n",
        "\n",
        "https://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "j5_jZkVj367x",
        "outputId": "014de203-973e-44b4-d82c-201a2349412e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp38-cp38-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.5/735.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (4.64.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0 torchtext-0.9.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\\n\\ntorchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\\npip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\\n\\nhttps://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1027\n",
        "\n",
        "\"\"\" @\n",
        "딥러닝에서 초기화를 위해 random num 사용\n",
        "-> random number 많이 사용\n",
        "-> 실험마다 다른 값의 연산으로 결과 달라질 수 있음\n",
        "-> 따라서, 실험을 동일하게 진행하기 위해 동일한 난수 필요 (재생산성 유지)\n",
        "-> (pytorch) random seed를 구정하기 위한 함수 -> manual_seed \n",
        "∴ 랜덤시드 고정 함수 = torch.manual_seed() \n",
        "  \n",
        "https://rabo0313.tistory.com/entry/pytorch-torchmanualseed\n",
        "\"\"\"\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "\"\"\"\n",
        " deterministic ex. a deterministic view of life\n",
        " Deterministic한 알고리즘'만' 사용하게 하기 \n",
        " Sets whether PyTorch operations must use “deterministic” algorithms.\n",
        " That is, algorithms which, given the same input, and when run on the same software and hardware, always produce the same output\n",
        " cudnn에서 수행하는 연산에 대해 적용하기 = True\n",
        " *  cudnn(cuda deep neural network) is a GPU-accelerated library of primitives for deep neural networks\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n"
      ],
      "metadata": {
        "id": "d_pchz0J3xxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "구글 드라이브 마운팅"
      ],
      "metadata": {
        "id": "0PQPGJu54NUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1K5U5Zm34yh",
        "outputId": "44eca74a-d667-44bd-e7be-4eaf5f778db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd # 현재 경로 확인 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9O-wsPjT3nj_",
        "outputId": "58de3275-d4a4-42b0-f401-cea0c524ab99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/논문/sentimentP/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMSvgsd64XuN",
        "outputId": "0b2753fa-cd68-4bd4-9ad8-c71b89391ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/논문/sentimentP/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QxKqb7bA5MnF",
        "outputId": "bf01efa3-bb29-4881-f466-e3fc5b47bc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/논문/sentimentP/dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVSPyTjO5dzm",
        "outputId": "9fbf83cc-47f5-4ffb-c8bb-5052bc84559d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMecab-ko-for-Google-Colab\u001b[0m/  ratings_train.txt  train_data.csv\n",
            "ratings_test.txt            test_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리\n",
        "> Filed 지정 / KoNLPy의 은전한닢(Mecab) tokenizer 이용"
      ],
      "metadata": {
        "id": "7J-BU7987OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 내 다운로드 https://wikidocs.net/94600\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVimlTus405w",
        "outputId": "31639344-76dd-4e4d-dc5d-b52bedabfb0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/논문/sentimentP/dataset/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-01-28 08:03:15--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22c0:3470, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNH7VTG7TE&Signature=jNDJfEsKGKrivM9YnAVfAsgWDHM%3D&x-amz-security-token=FwoGZXIvYXdzEPH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDOAb%2FOJncaR9A2oioSK%2BAYqjtP7GhK6s%2FDdsbG%2BpRWycQpb2eeYysj%2Bt0hUudn0wxGHMcEHiAcFBMnxVDxJFddp7%2ByukaTAwpxcOoCkNVGkD%2FvErlkXxStFiJzKty6EFFC2cUlyYiGX9M1agIiHEpy6nkiIheqf6E5rqe17gIwxzNaePQAnXy3aBLvJcdo%2BdMn9Hb31rCBTHtyLGUkc9qd39o3SY5H62DM9OtuRaSK5s9xc4%2BPVb1BnWsyiFdePzxr4LuaEzjNnT4SjJJPsoxK3TngYyLSXdZT8%2BD%2FtIAQvk4VvcNTezmAzWJz3ng0K40j%2F5ANFHSMJ3Pst%2BEuFX0E4uYg%3D%3D&Expires=1674894796 [following]\n",
            "--2023-01-28 08:03:16--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNH7VTG7TE&Signature=jNDJfEsKGKrivM9YnAVfAsgWDHM%3D&x-amz-security-token=FwoGZXIvYXdzEPH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDOAb%2FOJncaR9A2oioSK%2BAYqjtP7GhK6s%2FDdsbG%2BpRWycQpb2eeYysj%2Bt0hUudn0wxGHMcEHiAcFBMnxVDxJFddp7%2ByukaTAwpxcOoCkNVGkD%2FvErlkXxStFiJzKty6EFFC2cUlyYiGX9M1agIiHEpy6nkiIheqf6E5rqe17gIwxzNaePQAnXy3aBLvJcdo%2BdMn9Hb31rCBTHtyLGUkc9qd39o3SY5H62DM9OtuRaSK5s9xc4%2BPVb1BnWsyiFdePzxr4LuaEzjNnT4SjJJPsoxK3TngYyLSXdZT8%2BD%2FtIAQvk4VvcNTezmAzWJz3ng0K40j%2F5ANFHSMJ3Pst%2BEuFX0E4uYg%3D%3D&Expires=1674894796\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.229.89, 52.216.44.9, 54.231.232.201, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.229.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  2.60MB/s    in 0.5s    \n",
            "\n",
            "2023-01-28 08:03:17 (2.60 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-01-28 08:05:04--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c0:3470, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNBVSXJKVY&Signature=21gKt6ILAK1wu4PwcpM2kqT0R1I%3D&x-amz-security-token=FwoGZXIvYXdzEPH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDAVGzFrrpcwB%2FZs2yiK%2BAUSRqMuhMtPzF%2BhY3grqKRo8j9Y8DIilu7NgvFI9l%2FeIkBSoTD%2BGG%2BCuNVo64yuvbMH04WoSkmIN2ILN9F5mLRYgneQx2Vamb1pnoiulCb%2BQQx4v7pgsRYj63dpgWu7ASahN8%2B5nP660MJ51kVu2mflJCxD5vAVjVfqpc2SFYR5NJwft4ioXnCE3Y%2BMQS6j%2Fcu3GegwWCewizyjN4%2Fq8HjMX2wEAAwuiPGQIRwH3tVGFR2775C3Dfzcgj1UfH2Aom6jTngYyLWXlGtl61O3ZEn5RTD8Jbm22o1C0yn7CHi9ckVP%2BoKrsOrgAr4DqvOCthxEuEQ%3D%3D&Expires=1674894115 [following]\n",
            "--2023-01-28 08:05:05--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNBVSXJKVY&Signature=21gKt6ILAK1wu4PwcpM2kqT0R1I%3D&x-amz-security-token=FwoGZXIvYXdzEPH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDAVGzFrrpcwB%2FZs2yiK%2BAUSRqMuhMtPzF%2BhY3grqKRo8j9Y8DIilu7NgvFI9l%2FeIkBSoTD%2BGG%2BCuNVo64yuvbMH04WoSkmIN2ILN9F5mLRYgneQx2Vamb1pnoiulCb%2BQQx4v7pgsRYj63dpgWu7ASahN8%2B5nP660MJ51kVu2mflJCxD5vAVjVfqpc2SFYR5NJwft4ioXnCE3Y%2BMQS6j%2Fcu3GegwWCewizyjN4%2Fq8HjMX2wEAAwuiPGQIRwH3tVGFR2775C3Dfzcgj1UfH2Aom6jTngYyLWXlGtl61O3ZEn5RTD8Jbm22o1C0yn7CHi9ckVP%2BoKrsOrgAr4DqvOCthxEuEQ%3D%3D&Expires=1674894115\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.205.185, 52.216.143.60, 52.216.236.115, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.205.185|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  21.9MB/s    in 2.2s    \n",
            "\n",
            "2023-01-28 08:05:07 (21.9 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "UtDEsT024qPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "* Pytorch에서 자연어 처리 라이브러리 토치텍스트(torchtext) 제공\n",
        "* 반드시 필요한 것은 아니나, 직접 구현보다 사용하는 것이 편하기도함\n",
        "* 토치 텍스트가 제공하는 기능들\n",
        "1) 파일 로드하기(File Loading) : 다양한 포맷의 코퍼스를 로드합니다.\n",
        "2) 토큰화(Tokenization) : 문장을 단어 단위로 분리해줍니다.\n",
        "3) 단어 집합(Vocab) : 단어 집합을 만듭니다.\n",
        "4) 정수 인코딩(Integer encoding) : 전체 코퍼스의 단어들을 각각의 고유한 정수로 맵핑합니다.\n",
        "5) 단어 벡터(Word Vector) : 단어 집합의 단어들에 고유한 임베딩 벡터를 만들어줍니다. 랜덤값으로 초기화한 값일 수도 있고, 사전 훈련된 임베딩 벡터들을 로드할 수도 있습니다.\n",
        "6) 배치화(Batching) : 훈련 샘플들의 배치를 만들어줍니다. 이 과정에서 패딩 작업(Padding)도 이루어집니다.\n",
        "*** 모든 전처리를 해결해주진 X ***\n",
        "* 검증데이터 분리 작업, 각 샘플에 대해 단어들을 임베딩 벡터로 매핑해주는 작업 (ex. nn.Embedding()을 통해서 lookup table 작업을 해결해야함)\n",
        "\n",
        "(출처) https://wikidocs.net/60314\n",
        "\"\"\"\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.legacy import data\n",
        "\n",
        "\"\"\"\"\n",
        "torchtext.legacy.data에서 제공하는 Field라는 도구를 통해 앞으로 어떤 전처리를 할 것인지 정의 \n",
        "필드는 어떻게 전처리를 진행할 것인지'만 정의! 실제 train data 전처리 진행 X\n",
        "\"\"\"\n",
        "TEXT = torchtext.legacy.data.Field(tokenize=mecab.morphs)\n",
        "LABEL = torchtext.legacy.data.LabelField(dtype = torch.float)"
      ],
      "metadata": {
        "id": "WYA02H685GhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__\n",
        "torchtext.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F9nWfROP6dCb",
        "outputId": "28ed7838-2030-4fbb-f840-259c47fd6f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.9.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torchtext 내 내장된 데이터셋 이용하는게 아니므로 컬럼별 해당 Field 지정"
      ],
      "metadata": {
        "id": "Y5LgoodH5koB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fields = {'text': ('text', TEXT), 'label': ('label', LABEL)}\n",
        "# dictionary 형식; {csv 컬럼명 : (데이터 컬럼명, Field이름)}"
      ],
      "metadata": {
        "id": "piJA-nb56ttT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "* 필드 지정 -> *데이터셋 만들기!* \n",
        "* TabularDataset은 데이터 불러오면서 필드에서 정의했던 토큰화 방법으로 토큰화 수행 \n",
        "  (소문자와 같은 기본적인 전처리도 함께 진행)\n",
        "\"\"\"\n",
        "train_data, test_data = data.TabularDataset.splits(\n",
        "    path = '.', # 파일이 위치한 경로 \n",
        "    train = 'train_data.csv',\n",
        "    test = 'test_data.csv',\n",
        "    format = 'csv', # 데이터의 포맷 \n",
        "    fields = fields # 위에서 지정한 필드 지정 \n",
        ")"
      ],
      "metadata": {
        "id": "zmCRdQD48RTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "vars() 통해 주어진 인덱스의 샘플 확인\n",
        "* TabularDataset을 통해 정의한 필드로 구성되어지며 토큰화 진행되었음 \n",
        "\"\"\"\n",
        "vars(train_data[0]), vars(train_data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70A2dcp8ZTG",
        "outputId": "d4eb79f2-242e-4826-9f1c-e1260437bac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'text': ['아', '더', '빙', '.', '.', '진짜', '짜증', '나', '네요', '목소리'],\n",
              "  'label': '0'},\n",
              " {'text': ['흠',\n",
              "   '.',\n",
              "   '..',\n",
              "   '포스터',\n",
              "   '보고',\n",
              "   '초딩',\n",
              "   '영화',\n",
              "   '줄',\n",
              "   '.',\n",
              "   '...',\n",
              "   '오버',\n",
              "   '연기',\n",
              "   '조차',\n",
              "   '가볍',\n",
              "   '지',\n",
              "   '않',\n",
              "   '구나'],\n",
              "  'label': '1'})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'훈련 데이터 수: {len(train_data)}')\n",
        "print(f'테스트 데이터 수: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPuMgbF18zEc",
        "outputId": "ab63718f-1a8b-4228-8e4d-5abdcbd9d62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터 수: 149995\n",
            "테스트 데이터 수: 49997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 검증데이터 별도 생성"
      ],
      "metadata": {
        "id": "YmK9NEtt8-h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "metadata": {
        "id": "07qme4jX9CbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'훈련데이터 수 : {len(train_data)}')\n",
        "print(f'검증 데이터 수 : {len(valid_data)}')\n",
        "print(f'테스트 데이터 수 : {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NfnhTIh9I6Z",
        "outputId": "eeaf050e-3fa6-401c-ac84-2bdad679ecb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련데이터 수 : 104996\n",
            "검증 데이터 수 : 44999\n",
            "테스트 데이터 수 : 49997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단어집합 만들기 *총 단어의 수 확인\n",
        "> [Q] vocab의 역할? 토큰화 이후, 중복 단어 고려하며 vocab 생성 -> 고유 단어별 정수화해주는 역할?"
      ],
      "metadata": {
        "id": "sCiduXqL849A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "* 토큰화 전처리를 끝냈다면 이제 각 단어에 고유한 정수를 맵핑해주는 정수 인코딩 작업이 필요! \n",
        "이 전처리 작업을 위해 단어 집합이 필요함!\n",
        "HOW? 정의한 필드에 build.vocab()도구를 사용하며 단어 집합 생성 \n",
        "\"\"\"\n",
        "TEXT.build_vocab(train_data)\n",
        "len(TEXT.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvRMxGfd9pXS",
        "outputId": "e27d6ff4-d6a6-4b5b-9bdf-c553642de489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45983"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최소 두 번 이상 등장하는 단어의 갯수\n",
        "TEXT.build_vocab(train_data, min_freq=2) #  min_freq;단어 집합에 추가 시 단어의 최소 등장 빈도 조건을 추가\n",
        "len(TEXT.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOCoXBaw93oi",
        "outputId": "972361cc-cc76-411c-b924-f5d6cf29e449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25292"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 25,000개로 끊어 실행"
      ],
      "metadata": {
        "id": "5JhtZt6w-E_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE) # max_size; 단어집합 최대 크기,\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "Qsk45f7_-MTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### unk, pad 토큰이 추가되어 단어의 갯수가 2개 추가됨 "
      ],
      "metadata": {
        "id": "UYuTv1exZ7rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "* 단어들에 일련의 번호를 부여해서 vocabulary를 생성 (문장의 길이를 맞추기 위한 <pad>, <unk> 추가 지정)\n",
        "* <pad> : padding. 길이를 맞출 때 사용하는 비어있는 토큰 \n",
        "* <unk> : unknown. 모델이 인식할 수 없는 토큰 ex. 지정한 vocab size 이상인 숫자는 모델이 인식하지 못하고 해당 토큰으로 바꿔 인식\n",
        "* <sos> : start of sentence(or sequence). 문장의 시작을 알리는 토큰 \n",
        "* <eos> : end of sequence\n",
        "(출처) : https://velog.io/@tmddn0311/RNN-tutorial\n",
        "\"\"\"\n",
        "print(f\"TEXT 단어장의 개수 : {len(TEXT.vocab)}\")\n",
        "print(f\"LABEL 단어장의 갯수 : {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Taud6Kv0ZROk",
        "outputId": "63d4ac0d-4b7b-45b8-b743-4a0a0552932c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXT 단어장의 개수 : 25002\n",
            "LABEL 단어장의 갯수 : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 최빈단어 확인해보기"
      ],
      "metadata": {
        "id": "iHfgMKQraF-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO6Nc973aI6v",
        "outputId": "fe4d9352-1120-4c80-f7f3-69ea84db6082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('.', 111878), ('이', 51558), ('는', 46843), ('영화', 40324), ('다', 39082), ('고', 33105), ('하', 31175), ('도', 23860), ('의', 23557), ('가', 23373), ('은', 21774), ('에', 21621), ('을', 20954), ('보', 17907), ('한', 17722), ('..', 15987), ('게', 15597), (',', 15423), ('들', 15125), ('!', 13655)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단어와 인덱스 사이 매핑 확인해보기\n",
        "> [Q] 매핑되었다 = 함께 조합하여 보여준다 (?) "
      ],
      "metadata": {
        "id": "SS2DcsLOaRHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\"\n",
        "List mapping indices to tokens. *indice; index 복수\n",
        "(출처) : https://pytorch.org/text/stable/vocab.html\n",
        "\"\"\"\n",
        "print(TEXT.vocab.itos[:10]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGCr5E4-aTgx",
        "outputId": "ed36a88c-00d3-48ac-9d3f-fdb723cb201e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', '.', '이', '는', '영화', '다', '고', '하', '도']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dictionary mapping tokens to indices.\n",
        "string 데이터를 사전의 index로의 변환을 제공함 \n",
        "\"\"\"\n",
        "print(TEXT.vocab.stoi) # 보통 <unk> 0번, <pad> 1번 부여함\n",
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxRwFtySaVlW",
        "outputId": "070e390a-2474-48f4-8c03-8d5b3df23ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'0': 0, '1': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BuketIterator를 이용하여 데이터 생성자 만들기\n",
        "> [Q1] batch size => 한번에 얼마나 많은 input(text)가 들어갈지 결정 </br>\n",
        "      ex) 기준은 원본 텍스트 1행?  토큰화 이후 임베딩된 토큰(vocab) 1개 기준? \n",
        "          각 행 -> 토큰화 이후 임베딩 -> 텐서로 표현됨 -> HELLO = [[0.1., 0.9., 0.8]] 이런 텐서?로 표현된 입력 텍스트가 기준이 되는 것인지..\n",
        "\n",
        "> [Q2] Iterator를 변환한다 = Iterator의 개념은 '전체 데이터에 대해 총 Batch의 수'\n",
        "\n",
        "> [Q3] 배치 내에서 sort한다는 것의 의미는? \n",
        "\n",
        "\n",
        "> [Q4] cuda의 개념 * cudnn 란? \n",
        "\n"
      ],
      "metadata": {
        "id": "q2py_-SKaX8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "\"\"\"\n",
        "gpu에 연산이 할당됨 \n",
        "* 시스템상 여러개의 gpu가 연결되어 있다면, 그 일부가 다른 gpu로 할당되는 현상이 일어남\n",
        "\"\"\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "BucketIterator : Defines an iterator that batches examples of similar lengths together.\n",
        "classtorchtext.data.BucketIterator(dataset, batch_size, sort_key=None, device=None, batch_size_fn=None, train=True, repeat=False, shuffle=None, sort=None, sort_within_batch=None)\n",
        "\n",
        "* Pytorch의 dataloader(group examples from the PyTorch Dataset)와 비슷한 역할 (* 다른점? 비슷한 길이의 문장들끼리 batch 만들기 때문에 padding 개수 최소화) \n",
        "* 모든 텍스트 작업을 일괄로 처리하고, 단어를 인덱스 숫자로 변환하는 것을 도움\n",
        "* iterator(반복자) 배열이나 유사한 자료 구조의 내부 요소를 순회하기 위한 객체 \n",
        "* (더 읽어보기) https://gmihaila.github.io/tutorial_notebooks/pytorchtext_bucketiterator/\n",
        "\"\"\"\n",
        "# Group similar length text sequences together in batches.\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), # Tuple of train, validation and test batch sizes\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device, # Device to load batches on.\n",
        "    sort_key = lambda x: len(x.text), # # Function to use for sorting examples.\n",
        "    sort_within_batch = False, # Don't Use `sort_key` to sort examples in each batch.\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "D5ZmsBZiaccO",
        "outputId": "66534270-3db6-4302-e1dd-a0d6153bb445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-86f5ca6efbba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m반복자\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0m배열이나\u001b[0m \u001b[0m유사한\u001b[0m \u001b[0m자료\u001b[0m \u001b[0m구조의\u001b[0m \u001b[0m내부\u001b[0m \u001b[0m요소를\u001b[0m \u001b[0m순회하기\u001b[0m \u001b[0m위한\u001b[0m \u001b[0m객체\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \"\"\"\n\u001b[0;32m---> 15\u001b[0;31m train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchtext.data' has no attribute 'BucketIterator'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 생성된 데이터 크기 확인해보기\n",
        "\n",
        "> [Q] tensor size 이해한게 맞는지.."
      ],
      "metadata": {
        "id": "ZTFMoykja3bS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "파이썬 내장함수 ; iter, next\n",
        "* iter : 객체의 __iter__ 메서드 호출 -> 반복가능한 객체에서 이터레이트를 발환 \n",
        "* next : __next__ 메서드 호출 -> 이터레이터에서 값을 차례대로 꺼냄\n",
        "\"\"\"\n",
        "next(iter(train_iterator)).text.shape # 문장의 길이(text 최대 크기) * 배치 사이즈 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKRckR_ma6TZ",
        "outputId": "e483f092-478f-4bf5-b1b5-3146765dde0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([73, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 생성하기\n",
        "> 바닐라 RNN을 이용하여 간단한 모델을 생성. 모델의 각 input/output 벡터의 사이즈는 다음과 같음\n",
        "* text : [sentence length, batch size]\n",
        "* embedded : [sentence length, batch_size, embedding dim]\n",
        "* output : [sentence length, batch size, hidden dim]\n",
        "* hidden : [1, batch size, hidden dim]\n",
        "# https://justkode.kr/deep-learning/pytorch-rnn</br>\n",
        "\n",
        "\n",
        "> [Q1] input data = sequence length </br>\n",
        "  input data shape = ( batch size, sequence length, dimension) \n",
        "  \n",
        "\n",
        "\n",
        "> [Q2] Dimension의 개념.. 이해한 것 설명해보기 </br> \n",
        "   ex) embedding dimension, hidden dimension </br>\n",
        "\n",
        "   \"\"\"</br>\n",
        "   \"차원 or피처의 개수\"</br> \n",
        "   1차원 직선, 2차원 평면과 같이 x, y 축으로 나타내는 '축' = dimension </br>\n",
        "   (ML) 데이터를 표현하는데 필요한 축 'dimension' => feature의 개수 = dimension </br> ex) 정규분표의 경우, 평균, 표준편차 두 변수가 있음. feature 개수 2개 = 2-Dimension임 \n",
        "\n",
        "   \"\"\"</br>\n",
        "\n",
        "> [Q3] hidden dimension의 개념? 작동방법? \n",
        "   hidden_state = output data로 몇 차원의 vector를 출력받을지 결정 \n",
        "   hidden_size = 2 = output_size( , , 2) \n",
        "   HOW? 출력 직전에 output size, hidden size로 나뉘게됨 "
      ],
      "metadata": {
        "id": "cuTHb8sybiQv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsBgd88FUHYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "pTmU7UncbjUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "    self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  \n",
        "  def forward(self, text):\n",
        "    # text : [sent_len, batch_size]\n",
        "    embedded = self.embedding(text)\n",
        "    # embedded : [sent_len, batch_size, emb_dim]\n",
        "    output, hidden = self.rnn(embedded)\n",
        "    # output : [sent_len, batch_size, hidden_dim]\n",
        "    # hidden : [1, batch_size, hidden_dim]\n",
        "    assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "\n",
        "    return self.fc(hidden.squeeze(0)) # [batch_size, output_dim]"
      ],
      "metadata": {
        "id": "hTqASmqib_RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델의 하이퍼파라미터를 다음과 같이 설정한 후 불러오기"
      ],
      "metadata": {
        "id": "UhSNXV1ac4pS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "kjTc2d7uc7r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이 모델의 파라미터 수를 다음과 같이 추출 "
      ],
      "metadata": {
        "id": "CwK0lOIEdQyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'이 모델은 {count_parameters(model):,} 개의 파라미터를 가지고 있습니다.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPbawYD2dtri",
        "outputId": "62ebf5b6-ace4-4a21-dfc5-f0525d222211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 모델은 2,592,105 개의 파라미터를 가지고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 훈련\n",
        "> SGD optimizer를 이용하여 모델 훈련\n",
        "\n",
        "[Q1]  Optimizer의 개념 = parameter 어떻게? 업데이트 할 것인가 ex. SGD, Adam etc \n",
        "\n",
        "</br> 손실함수(Loss function)와 다른 개념?</br> \n",
        "[Q2] 손실함수는 forward-backward하면서loss를 계산하는 방식?\n",
        "\n",
        "> Optimizer은 backward할 때 어떻게 각각의 파라미터(w, b)를 업데이트 해줄 것인가?"
      ],
      "metadata": {
        "id": "oZh0J2RqeXKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "BO5oKgaYebsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 손실함수는 bianry cross entropy with logits\n",
        "> 임의의 실수를 입력으로 받아서 sigmoid 함수를 취해 0과 1 사이의 값으로 변환한 뒤 label과의 binary cross entropy를 계산함"
      ],
      "metadata": {
        "id": "a2MmfVHJeyKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "DbulQJMAfA4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델과 손실함수를 GPU에 올리자"
      ],
      "metadata": {
        "id": "zc7m8vRffFr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "lURV8Oc8fW_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이제 평가를 위해 임의의 실수를 0과 1 두 정수 중 하나로 변환하는 함수를 만들자"
      ],
      "metadata": {
        "id": "ubLo0J8sfapP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "  rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "  correct = (rounded_preds == y).float()\n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ],
      "metadata": {
        "id": "N6xRh2qsffDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델의 훈련과 평가를 위한 함수를 만들기 \n",
        "> model의 output size는 [batch_size, output_dim]임. output_dim=1이므로 이 차원을 없애줘야 label과 비교할 수 있어 squeeze(1)를 적용함\n",
        "\n",
        "\n",
        "> [Q] 루프 = Iterator "
      ],
      "metadata": {
        "id": "6WtmMMy3fwXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train() \n",
        "\n",
        "  \"\"\"\n",
        "  * optimizer.zero_grad()\n",
        "  루프가 한번 돌고나서 역전파 하기 전에 반드시 zero_grad()로 .grad값들을 0으로 초기화시킨 후 학습 진행해야함 \n",
        "  why? 안그러면 이전 루프에 저장된 grad가 다음 루프의 업뎃에도 간섭하게됨 \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    acc = binary_accuracy(predictions, batch.label)\n",
        "  \n",
        "  \"\"\"\n",
        "  한 루프에서 업뎃 위해 loss.backward() 호출 -> 각 파라미터들의 grad값에 변화 \n",
        "  \"\"\"\n",
        "    loss.backward()\n",
        "\n",
        "  \"\"\"\n",
        "  backward하며 미분 -> 손실함수에 끼친 영향력(변화량) 구하고 optimizer step을 통해 손실함수를 최적화하도록 파라미터를 업데이트함 \n",
        "  \"\"\"\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item() # tensor에 item()을 취하면 value를 반환함\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "metadata": {
        "id": "TNC32iDEf_tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 평가를 위한 함수는 그래디언트 업데이트를 하지 않아야 하므로 with torch.no_grad(): 구문으로 감싸도록 함\n",
        "\n",
        "> [Q] overftting의 기준? 예측값과 실제값의 정확도가 5% 이상 차이나면 보통 오버피팅이라고하는지..? \n"
      ],
      "metadata": {
        "id": "TelYIWf5ghPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  \n",
        "  \"\"\"\n",
        "  model 학습 후 모델 평가할 때 model.eval 입력하고 시작 -> model이 학습을 끝낸 후, model.eval()을 통해 평가모드로 바꾸겠다는 의미\n",
        "  Why? 훈련모드와 평가모드는 구조가 다르기 때문에- 평가모드엔 다른른 layer가 있기 때문에 \n",
        "  \"\"\"\n",
        "  model.eval() # 이 모델은 상관없음\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      predictions = model(batch.text).squeeze(1)\n",
        "      loss = criterion(predictions, batch.label)\n",
        "      acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss/len(iterator), epoch_acc/len(iterator)\n",
        "      "
      ],
      "metadata": {
        "id": "ETUdGHMjf0sP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "1cee0f80-5e51-4cff-fab8-67ac3904db01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-5ab9f593672b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    epoch_acc =\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### epoch마다 걸린 훈련시간을 측정하는 함수 "
      ],
      "metadata": {
        "id": "E9iocZOrhhdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "5eWuAkzuhk-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실제 훈련시키기 * 검증셋의 손실이 개선되면 모델을 저장하도록 구현 "
      ],
      "metadata": {
        "id": "viOXLYVhh0Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')"
      ],
      "metadata": {
        "id": "Ua07rvEch5CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "  start_time = time.time()\n",
        "\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  if valid_loss < best_valid_loss: \n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'tutl-model.pt')\n",
        "\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\t Train Loss: {train_loss:.3f} | Train Acc : {train_acc*100:0.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} | Val Acc: {valid_acc*100:0.2f}% ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABbifJrth8zg",
        "outputId": "adc04a6d-f99f-4994-a045-a48ca31b5212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 4m 56s\n",
            "\t Train Loss: 0.693 | Train Acc : 49.79%\n",
            "\t Val. Loss: 0.695 | Val Acc: 50.89% \n",
            "Epoch: 02 | Epoch Time: 4m 31s\n",
            "\t Train Loss: 0.693 | Train Acc : 50.18%\n",
            "\t Val. Loss: 0.694 | Val Acc: 51.17% \n",
            "Epoch: 03 | Epoch Time: 4m 30s\n",
            "\t Train Loss: 0.693 | Train Acc : 50.13%\n",
            "\t Val. Loss: 0.693 | Val Acc: 51.51% \n",
            "Epoch: 04 | Epoch Time: 4m 31s\n",
            "\t Train Loss: 0.693 | Train Acc : 49.80%\n",
            "\t Val. Loss: 0.693 | Val Acc: 52.38% \n",
            "Epoch: 05 | Epoch Time: 4m 28s\n",
            "\t Train Loss: 0.693 | Train Acc : 50.18%\n",
            "\t Val. Loss: 0.692 | Val Acc: 52.92% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  모델의 성능이 좋지 않아 훈련이 거의 되지 않음을 확인할 수 있었음 "
      ],
      "metadata": {
        "id": "HkXuFLbNi9so"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 검증 셋에서 가장 좋은 결과를 받은 모델 기준으로 테스트셋의 결과를 측정해보기"
      ],
      "metadata": {
        "id": "tKwk1bqyjGM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tutl-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc : {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e6tlRvze2gN",
        "outputId": "c79a4867-7fd3-41d8-cc64-9c612568386e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.692 | Test Acc : 53.06%\n"
          ]
        }
      ]
    }
  ]
}