{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0yacinek0/nlp/blob/practice/%5Bgithub_nlp%5D_2_%ED%96%A5%EC%83%81%EB%90%9C_%EB%B6%84%EC%84%9D_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B0%94%EA%BF%94%EB%B3%B4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL: BI-LSTM"
      ],
      "metadata": {
        "id": "d9CY71wA1rxX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JVHDYztaLNC"
      },
      "source": [
        "### 구글 드라이브 마운팅 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89nDbiwYaMkX",
        "outputId": "9dddc21b-cb58-4f9e-c7c8-fa5e8f9b6c49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ToTK22XpaMpc",
        "outputId": "365b0fe8-4ebd-4924-ff5c-4c72f396a32f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "pwd # 현재 경로 확인 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj4Cz3dqaMuj",
        "outputId": "7c5ab513-25dc-43ca-d538-fdbb67647e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/논문/datasets\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/논문/datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VLQTFknfaMzc",
        "outputId": "7870e630-a874-482b-8562-3f3ca08addb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/논문/datasets'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJDqVvHFaM2k",
        "outputId": "ec09eca2-837d-4d10-b0cc-1f7227bf6476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "koas_data_test.csv      \u001b[0m\u001b[01;34mMecab-ko-for-Google-Colab\u001b[0m/\n",
            "koas_data_training.csv  tutl-model.pt\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbv1p9Ct3t8_"
      },
      "source": [
        "### 필요한 패키지와 랜덤시드 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "j5_jZkVj367x",
        "outputId": "ff87d1ea-e6ec-4ac6-d62e-46665ca00201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp38-cp38-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.5/735.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0 torchtext-0.9.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\\n\\ntorchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\\npip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\\n\\nhttps://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# !pip install torchtext==0.10.1 \n",
        "!pip install torch==1.8.0 torchtext==0.9.0\n",
        "\"\"\"\n",
        "아마 예전 코드를 실행하시면서 지금은 사라진 객체를 생성하시려다가 생기는 오류 같습니다.\n",
        "\n",
        "torchtext 버전을 0.10.x 이나 그 이전으로 낮춰보시는 것은 어떠실까요?\n",
        "pip install torchtext==0.10.1 과 같은 식으로 버전을 지정하셔서 설치하실 수 있습니다.\n",
        "\n",
        "https://stackoverflow.com/questions/73055161/importerror-cannot-import-name-unicode-csv-reader-from-torchtext-utils\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d_pchz0J3xxp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1027\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J-BU7987OMn"
      },
      "source": [
        "# 전처리\n",
        "> Filed 지정 / KoNLPy의 은전한닢(Mecab) tokenizer 이용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVimlTus405w",
        "outputId": "efbbf5de-b5fe-4c77-9f89-e071ae5d4ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/논문/datasets/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.22.4)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (23.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-03-07 06:54:23--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.2, 18.205.93.1, 18.205.93.0, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKWMWIROS&Signature=5p4xDgt2sHmTLCd8OsXUdVA6xL0%3D&x-amz-security-token=FwoGZXIvYXdzEID%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDIZQ4sxD4tv9t48psCK%2BAcyJqJxq6bfwK5F4J43EMrN63wMr%2FmyVYljBxH3BHNpBfdoZ7Vw%2FX%2BIj6V2FV18mt8We4Am%2F6QGHx67lXVjJH%2BiwTMF3KjrzK7%2FtdyP7bDnsMtFYyByEs1yNjzBRgCk72OU3MDSW7HfHgQGvWgA81PAJiuzWGQPgskH1GrKCKUaNdIV47ofIWkXfftkWwdSSyRLjCm%2BzHkZzk59QgUMh0YWuLREQ%2F3rQq%2B3MyyyclJGYeQqKzg%2BrstzbAe2yLNEo67yboAYyLd7ZIEtjcw5zCQN4N9t9bko2ivy5pc3vUmrf5IP4%2FOSTRNmJvHxLysDuVFtrFg%3D%3D&Expires=1678173555 [following]\n",
            "--2023-03-07 06:54:23--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKWMWIROS&Signature=5p4xDgt2sHmTLCd8OsXUdVA6xL0%3D&x-amz-security-token=FwoGZXIvYXdzEID%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDIZQ4sxD4tv9t48psCK%2BAcyJqJxq6bfwK5F4J43EMrN63wMr%2FmyVYljBxH3BHNpBfdoZ7Vw%2FX%2BIj6V2FV18mt8We4Am%2F6QGHx67lXVjJH%2BiwTMF3KjrzK7%2FtdyP7bDnsMtFYyByEs1yNjzBRgCk72OU3MDSW7HfHgQGvWgA81PAJiuzWGQPgskH1GrKCKUaNdIV47ofIWkXfftkWwdSSyRLjCm%2BzHkZzk59QgUMh0YWuLREQ%2F3rQq%2B3MyyyclJGYeQqKzg%2BrstzbAe2yLNEo67yboAYyLd7ZIEtjcw5zCQN4N9t9bko2ivy5pc3vUmrf5IP4%2FOSTRNmJvHxLysDuVFtrFg%3D%3D&Expires=1678173555\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 3.5.17.197, 54.231.235.217, 52.217.194.209, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|3.5.17.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  8.71MB/s    in 0.2s    \n",
            "\n",
            "2023-03-07 06:54:23 (8.71 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-03-07 06:56:31--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.0, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNONEMUMEK&Signature=Q3BsG1DJQG8JE0zt7iCOdwMssX8%3D&x-amz-security-token=FwoGZXIvYXdzEID%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDNRAqXeMC%2FtZgrMspSK%2BAdCQm9yR6AxNPA5UhyVt%2FDIaqgRNej0WzMP0aAlmU4EmLaS7w4lIQsKInF%2BWeJyo49kqvNY3CXYR3o382D2awth7ZRnI6jYWFcM9ZO97C5ysOKgYW4CZoLKT1lGCQtYVs6DxRq7f8iWv1mxT%2BnzPZs9aRtoKERwr2h7ekIfLR4jXw6%2Bk1EAMva2Yy2ZKg18dBWQKEFAZogIZM6tyJz5v1frKExAp9yM%2FPI3MDP4urf3SS4Ls9gDuWLLO3fHUSHYoqLyboAYyLZXAcVxx9dl0%2FczSoaP1%2FTS3FHDV0ULPEeN4Q%2FLRsQzOjadOyAmDCH6myBSxcg%3D%3D&Expires=1678173488 [following]\n",
            "--2023-03-07 06:56:31--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNONEMUMEK&Signature=Q3BsG1DJQG8JE0zt7iCOdwMssX8%3D&x-amz-security-token=FwoGZXIvYXdzEID%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDNRAqXeMC%2FtZgrMspSK%2BAdCQm9yR6AxNPA5UhyVt%2FDIaqgRNej0WzMP0aAlmU4EmLaS7w4lIQsKInF%2BWeJyo49kqvNY3CXYR3o382D2awth7ZRnI6jYWFcM9ZO97C5ysOKgYW4CZoLKT1lGCQtYVs6DxRq7f8iWv1mxT%2BnzPZs9aRtoKERwr2h7ekIfLR4jXw6%2Bk1EAMva2Yy2ZKg18dBWQKEFAZogIZM6tyJz5v1frKExAp9yM%2FPI3MDP4urf3SS4Ls9gDuWLLO3fHUSHYoqLyboAYyLZXAcVxx9dl0%2FczSoaP1%2FTS3FHDV0ULPEeN4Q%2FLRsQzOjadOyAmDCH6myBSxcg%3D%3D&Expires=1678173488\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.74.116, 52.216.76.188, 3.5.8.170, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.74.116|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M   104MB/s    in 0.5s    \n",
            "\n",
            "2023-03-07 06:56:32 (104 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ],
      "source": [
        "# 코랩 내 다운로드 https://wikidocs.net/94600\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UtDEsT024qPG"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WYA02H685GhZ"
      },
      "outputs": [],
      "source": [
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.legacy import data\n",
        "\n",
        "TEXT = torchtext.legacy.data.Field(tokenize=mecab.morphs, include_lengths = True)\n",
        "LABEL = torchtext.legacy.data.LabelField(dtype = torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F9nWfROP6dCb",
        "outputId": "780fe86c-596c-4055-e2c4-78f2dfca4fa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.9.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "torch.__version__\n",
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5LgoodH5koB"
      },
      "source": [
        "### torchtext 내 내장된 데이터셋 이용하는게 아니므로 컬럼별 해당 Field 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "piJA-nb56ttT"
      },
      "outputs": [],
      "source": [
        "fields = {'sentences': ('text', TEXT), 'Sentiment': ('label', LABEL)}\n",
        "# dictionary 형식; {csv 컬럼명 : (데이터 컬럼명, Field이름)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zmCRdQD48RTt"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = data.TabularDataset.splits(\n",
        "    path = '/content/drive/MyDrive/논문/datasets',\n",
        "    train = 'koas_data_training.csv',\n",
        "    test = 'koas_data_test.csv',\n",
        "    format = 'csv',\n",
        "    fields = fields\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70A2dcp8ZTG",
        "outputId": "562c964d-45cb-44e8-a2d4-bc52d1091632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'text': ['쯔양',\n",
              "   '이',\n",
              "   '댓글',\n",
              "   '안',\n",
              "   '달',\n",
              "   '았',\n",
              "   '으면',\n",
              "   '복귀',\n",
              "   '해도',\n",
              "   '다',\n",
              "   '들',\n",
              "   '뭐',\n",
              "   '라',\n",
              "   '안',\n",
              "   '하',\n",
              "   '지'],\n",
              "  'label': '1'},\n",
              " {'text': ['완벽',\n",
              "   '하',\n",
              "   '게',\n",
              "   '한글',\n",
              "   '화',\n",
              "   '되',\n",
              "   '어',\n",
              "   '있',\n",
              "   '습니다',\n",
              "   '.',\n",
              "   '제',\n",
              "   '가',\n",
              "   '처음',\n",
              "   '으로',\n",
              "   '한',\n",
              "   '셜록',\n",
              "   '홈즈',\n",
              "   '시리즈',\n",
              "   '이',\n",
              "   '긴',\n",
              "   '한데',\n",
              "   '몰',\n",
              "   '입도',\n",
              "   '가',\n",
              "   '매우',\n",
              "   '좋',\n",
              "   '았',\n",
              "   '습니다',\n",
              "   '.',\n",
              "   '다만',\n",
              "   '좀',\n",
              "   '뜬금없',\n",
              "   '는',\n",
              "   '단서',\n",
              "   '를',\n",
              "   '통해',\n",
              "   '스토리',\n",
              "   '를',\n",
              "   '진행',\n",
              "   '해야',\n",
              "   '하',\n",
              "   '는',\n",
              "   '경우',\n",
              "   '도',\n",
              "   '있',\n",
              "   '으므로',\n",
              "   '정말',\n",
              "   '못',\n",
              "   '찾',\n",
              "   '겠',\n",
              "   '다',\n",
              "   '싶',\n",
              "   '으면',\n",
              "   '빨리',\n",
              "   '구글',\n",
              "   '검색',\n",
              "   '을',\n",
              "   '통해',\n",
              "   '넘기',\n",
              "   '는',\n",
              "   '것',\n",
              "   '도',\n",
              "   '방법',\n",
              "   '입니다',\n",
              "   '.'],\n",
              "  'label': '0'})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "vars(train_data[0]), vars(train_data[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPuMgbF18zEc",
        "outputId": "82fc2d5f-927a-4d19-bf8d-756ac566f115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터 수: 29800\n",
            "테스트 데이터 수: 8725\n"
          ]
        }
      ],
      "source": [
        "print(f'훈련 데이터 수: {len(train_data)}')\n",
        "print(f'테스트 데이터 수: {len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmK9NEtt8-h7"
      },
      "source": [
        "### 검증데이터 별도 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "07qme4jX9CbI"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NfnhTIh9I6Z",
        "outputId": "503a38c3-3d5e-4097-f915-9bdc12347528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련데이터 수 : 20860\n",
            "검증 데이터 수 : 8940\n",
            "테스트 데이터 수 : 8725\n"
          ]
        }
      ],
      "source": [
        "print(f'훈련데이터 수 : {len(train_data)}')\n",
        "print(f'검증 데이터 수 : {len(valid_data)}')\n",
        "print(f'테스트 데이터 수 : {len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeQYq6Gek346"
      },
      "source": [
        "# 단어 벡터는 전처리된 단어 벡터를 받아보기\n",
        "> * 한글을 지원하는 fasttext.simple.300d 사용 <br>\n",
        "> * 사전훈련된 단어집에 없는 단어는 0으로 처리하는 걸 방지하기 위해 unk_init = torch.Tensor.normal_옵션을 줌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCiduXqL849A"
      },
      "source": [
        "### 총 단어의 수 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Qsk45f7_-MTs"
      },
      "outputs": [],
      "source": [
        "MAX_VOCAB_SIZE = 20000\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size=MAX_VOCAB_SIZE,\n",
        "                 vectors = 'fasttext.simple.300d',\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6izlknClmYP",
        "outputId": "e97aa1fd-953b-4506-b462-88b06c9c3fe8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20002"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(TEXT.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX-JUcdHln8p",
        "outputId": "36ce5bb1-9428-48c8-ab6c-7c35ce783e50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None, {'2': 0, '1': 1, '0': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "LABEL.vocab.stoi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oyBz15Rlryw",
        "outputId": "d5687845-1400-44e8-870e-62af43b2fab7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['비타민',\n",
              "  'D',\n",
              "  '와',\n",
              "  '운동',\n",
              "  '이',\n",
              "  '면역력',\n",
              "  '에',\n",
              "  '중요',\n",
              "  '한',\n",
              "  '요소',\n",
              "  '라는',\n",
              "  '것',\n",
              "  '을',\n",
              "  '알',\n",
              "  '고',\n",
              "  '있',\n",
              "  '었',\n",
              "  '지만',\n",
              "  '성별',\n",
              "  ',',\n",
              "  '연령',\n",
              "  '별',\n",
              "  '로',\n",
              "  '어떠',\n",
              "  '한',\n",
              "  '영향',\n",
              "  '을',\n",
              "  '미쳐',\n",
              "  '면역력',\n",
              "  '향상',\n",
              "  '을',\n",
              "  '위해',\n",
              "  '평소',\n",
              "  '영양',\n",
              "  '상태',\n",
              "  '를',\n",
              "  '잘',\n",
              "  '유지',\n",
              "  '해야',\n",
              "  '하',\n",
              "  '는',\n",
              "  '동시',\n",
              "  '주',\n",
              "  '2',\n",
              "  '∼',\n",
              "  '4',\n",
              "  '회',\n",
              "  '씩',\n",
              "  ',',\n",
              "  '1',\n",
              "  '∼',\n",
              "  '2',\n",
              "  '시간',\n",
              "  '의',\n",
              "  '운동',\n",
              "  '을',\n",
              "  '꼭',\n",
              "  '하',\n",
              "  '는',\n",
              "  '것',\n",
              "  '이',\n",
              "  '좋',\n",
              "  '다는',\n",
              "  '것',\n",
              "  '을',\n",
              "  '알',\n",
              "  '게',\n",
              "  '되',\n",
              "  '었',\n",
              "  '습니다',\n",
              "  '.'],\n",
              " 'label': '0'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "vars(train_data.examples[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uDuznBpslu9L"
      },
      "outputs": [],
      "source": [
        "for i in range(len(train_data)):\n",
        "  if len(train_data.examples[i].text)==0:\n",
        "     print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2py_-SKaX8e"
      },
      "source": [
        "### BuketIterator를 이용하여 데이터 생성자 만들기\n",
        "* 데이터 생성자를 만드는데, 길이에 따라 정렬하도록 sort_within_batch = True옵션을 넣어줄 것을 원 튜토리얼에서 요구하나\n",
        "* 한글 데이터에선 오류가 발생하여 sort_key=lambda x:len(x.text) 문장을 먼저 넣어줘야 오류없이 작동함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "D5ZmsBZiaccO"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    # sort_within_batch = True,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch = True,\n",
        "    device = device\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rak9IFCrmxS9"
      },
      "source": [
        "### 패딩 제외 길이로 정렬된 (문장, 길이) 순의 데이터로 이루어져있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWgr5g7cmqGo",
        "outputId": "633af464-4bf0-465f-aa34-a88ce67b9479"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[11892,   618,   579,    98,    64,  2637,    80,   312,   276,     3,\n",
              "            638,   314,   801,   913,   444,  1172,   381,   105,   223,   145,\n",
              "            312,   254,  6362,  1572,  8143,     0,    22,   119,   693,   519,\n",
              "           3680,   529,  5080,   125,  1095,   222,  1286,  1963,   544,   138,\n",
              "             22,  6869,   282,   280,    22,   221,  1001,  2162,    49,   151,\n",
              "            252,   201,  6366,    10, 11747,  2623,   555,  3306,  5130,  4903,\n",
              "            630,   228,    83,   779],\n",
              "         [ 3191,    34,    53,    60,   831, 11125,     9,   147,    27,   172,\n",
              "           5401,    12,  3239,     9,     9,    72,   474,   181,     2,   393,\n",
              "           1304,   215,   323,  2795,     0,    69,  2157,     7, 11116,    34,\n",
              "             83,  5443,    18,   190,    12,   547,    18,   278,    11,   174,\n",
              "           1370,   310, 10817,  1721,    49,  1373,  1057,   214,   126,  7438,\n",
              "            117,   248,   668,    14,    71,   846,    23,   680,   204,    89,\n",
              "            283, 17098,    14,  1028],\n",
              "         [ 1233,    32,  2871,   916,     5,   231,     0,   419,   378,    45,\n",
              "             12,   138,    14,    32,  2887,    87,    45,  2025,     2,    10,\n",
              "           6099,   230,    61,   447,    23,   134,   188,   125,   794,    18,\n",
              "            556,     5,  2760,   648,   347,   575,   455,    60,  3032,  1179,\n",
              "          14363,   773,    11,   433,  1655,  1488,   212,    24,    52,    18,\n",
              "            736,    11,   760,    34,  1297,  2574,    27,  9543,    12, 18495,\n",
              "             75,     0,    95,  2525],\n",
              "         [    8,     4,   303,  7895,   133,  1111,  2217,   298,    93,    58,\n",
              "            465,   174,    46,    23,     3,  1193,     3,   416,   162,  1241,\n",
              "            268,  2399,    26,    14,  1647,   140,    49,   190,   421,    90,\n",
              "           3208,    15,  3483,     7,    12,   142,     2,  2451,    61,   117,\n",
              "           3016,  1837,  5132,    56,   757,   112,  7897,    24,    25,   154,\n",
              "            214,  4608,    10,    18,  9689,   299,    63,   111,   379,  1359,\n",
              "             16,   394,   169,    14],\n",
              "         [   22,   145,     9,   100,   299,  1905,    12,   325,    77,  6732,\n",
              "            301,   686,   567,   302,    39,    68,  1777,    12,   148,    30,\n",
              "             26,     5,    23,    94,   681,    51,    74,   607,     3,  4255,\n",
              "          18007,    55,     9,    69,   606,    88,  1286,   181,   820,  3870,\n",
              "              8,    30,     3,     4,   264,   252,    18,  2332,    25,    54,\n",
              "             68,   277,     3,   371,     5,    58,    79,    16,    62,  4607,\n",
              "             24,  2282,   194,  2343],\n",
              "         [  371,    10,    78,    16,    27,   106,  2843,   725,     2,    15,\n",
              "             10,   301,     2,   317,    13,     3,   231,   145,    12,  6318,\n",
              "             60,     4,   371,    90,  1647,    23,    22,  1981,   419,    10,\n",
              "           2013,     6,  9337,   680,  1842,  4245,    18,  5288,    10,   551,\n",
              "             84,   627,  6257,   551,     3,  5257,   120,    20,   291,    71,\n",
              "             10,   466,  3707,    11,    17,     5,   617,    16, 18609,  1355,\n",
              "             24,  4636,    92,    40],\n",
              "         [   10,     3,   230,    16,    50,    13, 11079, 10297,   113,     6,\n",
              "            212,  1070,   815,  4339,  1715,    68,   109,   111,    34,    33,\n",
              "            744,    26,     3,    31,   681,   353,     2,  1613,    95, 15744,\n",
              "              2,   272,     4,  1914,    14,  2300,  1885,    84,   106, 15725,\n",
              "              3,     3,  5261,    32,    54,  3950,  1710,    24,  3831,   131,\n",
              "              3, 19123,   132,    37,   513,     4,  2955,    16,   163,     4,\n",
              "           2063,   476,    14,    61],\n",
              "         [   35,   552,   829,    16,   122,     7,    33,   298,   151,    85,\n",
              "            578,    17,     9,  1271,    11,    72,   140,  1666,    19,   869,\n",
              "             12,    58,   208,  1479,  1647,    38,   344,  3840,    18,   426,\n",
              "              2,   919,  3882,  1126,  8302,   949,    89,    10,     2,     3,\n",
              "           1012,   946,  3177,    62,     2,    17,    35,   504,    82,   154,\n",
              "           1845,    40,   140,     6,  2202,    26,     3,    16, 12811,   123,\n",
              "            610,   103,   754,    92],\n",
              "         [  142,  3001,  1047,    16,    98,  2341,  5072,    83,    11,     8,\n",
              "             38,  5521,  9260,     3,  1874,    53,  8522,   802,     4,    32,\n",
              "          18929,  6768,     4,    40,   681,  9948,    24,  6403,   140,   230,\n",
              "            325, 11875,    18,     5,   195,    54,  4254,    22,    49, 15555,\n",
              "            897,  4559,   294,   778,  7140,     5,  1134,   204, 15379,   143,\n",
              "              7,  1351,     3,  1299,    39,   428,   342,    16,    11,    10,\n",
              "            295,   259,  2406,    18],\n",
              "         [   31,  2654,    52,    16,    60,  2283,   398,   324,    27,    64,\n",
              "            657,  1586,    31,    60,   154,  1587,  9560,    58, 11874,     4,\n",
              "          15646,     5,     5,     5,    76,  1145,     2,  3041,    42,    47,\n",
              "              0,     6,   107,     4,   191,   564,     2,    64,     0,   907,\n",
              "            159,   384,    12,  1658,    32,     6,    23,    12,   200,   253,\n",
              "             85,   542,   550,   309,   105,    16,   200,    16,    58,     2,\n",
              "           1454,     5,   256,    17],\n",
              "         [ 8371,     4,   420,    16,     5,   622,    50,   129,   378,    18,\n",
              "              4,    61,    25,   159,   608,    68,   355,   115,   698,   110,\n",
              "           9913,    15,     6,    23,    34,    27,     2,  5067,   175,     5,\n",
              "           4975,  7276,   274,    26,    63,    19,   446,  3566,    28,  1525,\n",
              "            166,    88,  2506,   124,    47,   496,   636,  1165,   478,    35,\n",
              "            144,   476,     5,    43,  3548,    16,  1568,    16,    94,    36,\n",
              "              4,  1816,   402,    58],\n",
              "         [   61,    26,   230,    16,    15,    26,    31,     3,    93,   281,\n",
              "            351,  2236,    25,   138,   542,     7,   155,    28,     5,    18,\n",
              "            531,    67,   205,    41,   245,    61,     5,   270,    35,     6,\n",
              "             40,     5,   386,    51,    47,    57,     8,    17,     4,   500,\n",
              "              5,  3283,     8,    93,  5209,    33,     4,  1673,   433,     3,\n",
              "          10992,  8438,     6,    11,   143,    16,    70,    16,   511,   698,\n",
              "           6611,    32,   374,   491],\n",
              "         [ 9811,    69,   829,    16,    55,    51,     2,   274,    77,    19,\n",
              "              2,   382,    25,     5,   157,   138,     2,    32,     7,    82,\n",
              "              4,    39,  2440,   484,   277,    17,     2,   289,    32,    19,\n",
              "            109,   484,    15,    39,   858,    79,  1973,   338,  1057,   569,\n",
              "             20,  2618, 11173,   100,  1655,  1240,   610,   203,     0,    37,\n",
              "            176,     3,    19,    37,    62,    16,    37,    24,    48,     5,\n",
              "             19,   331,     2,   530],\n",
              "         [   13,   189,    77,    24,     6,    15,     2,  3641,     2,    52,\n",
              "              2,    13,    24,   306,     2,   174,     2,    20,    24,   188,\n",
              "            128,    13,    13,   160, 18499,    24,     2,   508,    90,    20,\n",
              "            442,    13,     7,   160,   289,    81,     2,    39,   454,    20,\n",
              "             24, 12168,     6,    24,   816,  5448,   106,   565,   160,     7,\n",
              "            100,    39,    20,    80,   604,    16,   246,    24,    52,    20,\n",
              "             31,   646,    36,    16]]),\n",
              " tensor([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
              "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
              "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
              "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "next(iter(train_iterator)).text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5dd6y9kmu5_"
      },
      "source": [
        "# 모델 생성\n",
        "* multi-layered bi-directional LSTM 사용\n",
        "* dropout 적용\n",
        "* nn.utils.rnn.packed_padded_sequence 써서 패킹/언패킹 처리\n",
        "<br>\n",
        "* 최종 hidden size는 [num layers*num directions, batch size, hidden dim]임\n",
        "* 구체적으로 [forward_layer_0, backward_layer_0, forward_layer_1, backward_layer1, ..., forward_layer_n, backward_layer n] 같이 출력.\n",
        "* 꼭대기층의 hidden만 필요하므로 hidden[-2::]과 hidden[-1::]만 뽑아 concatenate할 예정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wnXV66_8n0LQ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FUthbp0Xn75v"
      },
      "outputs": [],
      "source": [
        "emb = nn.Embedding(3,5,padding_idx=1) \n",
        "test = torch.tensor([0, 1, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJSnA-tIoKJL",
        "outputId": "66b88f5c-fb84-4567-9910-88f47b7bdd08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3671,  0.3455, -0.6553, -0.6129,  0.0402],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 1.5196, -0.0796,  0.8051,  1.1754, -0.2861]],\n",
              "       grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "emb(test) # padding_idx에 해당하는 벡터는 0임"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eTdTCawxoZoG"
      },
      "outputs": [],
      "source": [
        "def print_shape(name, data):\n",
        "  print(f'{name} has shape {data.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yQdEbHyfEdKs"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
        "                n_layers, bidirectional, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
        "                          bidirectional=bidirectional, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        # text = [sent_len, batch_size]\n",
        "        #print_shape('text',text)\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # embedded = [sent_len, batch_size, emb_dim]\n",
        "        #print_shape('embedded', embedded)\n",
        "        \n",
        "        # pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        #print_shape('packed_output', packed_output)\n",
        "        #print_shape('hidden', hidden)\n",
        "        #print_shape('cell', cell)\n",
        "        \n",
        "        # unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        #print_shape('output', output)\n",
        "        #print_shape('output_lengths', output_lengths)        \n",
        "        \n",
        "        # output = [sent_len, batch_size, hi_dim * num_directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "        # hidden = [num_layers * num_directions, batch_size, hid_dim]\n",
        "        # cell = [num_layers * num_directions, batch_size, hid_dim]\n",
        "        \n",
        "        # concat the final forward and backward hidden layers\n",
        "        # and apply dropout\n",
        "        \n",
        "        #print_shape('hidden[-2,:,:]', hidden[-2,:,:])\n",
        "        #print_shape('hidden[-1,:,:]', hidden[-1,:,:])\n",
        "        #cat = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        #print_shape('cat', cat)\n",
        "\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "        #print_shape('hidden', hidden)\n",
        "        # hidden = [batch_size, hid_dim * num_directions]\n",
        "        \n",
        "        res = self.fc(hidden)\n",
        "        #print_shape('res', res)\n",
        "        return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNJ8LFt3EiEG"
      },
      "source": [
        "### 하이퍼파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_P4vTUoXElHD"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300 # fasttext dim과 동일하게 설정\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vPIklE2YEl0y"
      },
      "outputs": [],
      "source": [
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "           N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk7xlSlBEm7n"
      },
      "source": [
        "### 파라미터 갯수 세보기 \n",
        "* 앞 모델과 비교하여 월등하게 많은 파라미터 수를 확인할 수 있음 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49cYtE89Euyc",
        "outputId": "e5725403-3ba3-428a-c068-62821daaa355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이 모델은 8,720,857 개의 파라미터를 가지고 있다.\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'이 모델은 {count_parameters(model):,} 개의 파라미터를 가지고 있다.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oO_q2jOE0D3"
      },
      "source": [
        "### 사전 학습된 fasttxt모델의 단어 벡터를 embedding 레이어에 복사하여 담기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHzG4McIE75e",
        "outputId": "172edd75-cf55-41d1-fba4-ffdd149fee3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20002, 300])\n"
          ]
        }
      ],
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7reE5BKE9z8"
      },
      "source": [
        "### Dimension 체크"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez4cML8FFAig",
        "outputId": "f9b5069f-68c5-4a51-d6c5-e6248dc9ae13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20002, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model.embedding.weight.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edzGvXuhFGBp"
      },
      "source": [
        "### weight가 아니라 weight.data 에 덮어씌워야 한다는 걸 명심"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3j62hVKFCKL",
        "outputId": "a1dfec6d-b1e0-4ee7-e501-d853e4340f79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.1313, -1.2231,  0.7267,  ...,  0.4225, -1.4333,  0.6811],\n",
              "        [-1.7826,  0.5479,  0.8169,  ..., -0.5085, -0.2250, -1.0241],\n",
              "        [ 0.0569, -0.0520,  0.2733,  ..., -0.0695, -0.1606, -0.0989],\n",
              "        ...,\n",
              "        [-0.5899, -0.0625, -1.1037,  ..., -1.2469, -0.1112,  0.9017],\n",
              "        [ 0.7496, -0.1232,  0.6312,  ...,  0.6909,  0.0641,  1.4927],\n",
              "        [ 0.4377,  0.5227,  1.3720,  ...,  1.3790,  0.1214, -1.5727]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings) # copy_ 메서드는 인수를 현재 모델의 웨이트에 복사함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcsp2MzPFSJS"
      },
      "source": [
        "### unk와 pad는 수동으로 0벡터로 만들자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a92ddv-CFWgv",
        "outputId": "f8415b84-3290-4534-c21f-d70debbcab41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "UNK_IDX, PAD_IDX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bgq8Vw2HFYv7",
        "outputId": "18c4d70d-05cd-4267-d33f-6327b4213855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0569, -0.0520,  0.2733,  ..., -0.0695, -0.1606, -0.0989],\n",
            "        ...,\n",
            "        [-0.5899, -0.0625, -1.1037,  ..., -1.2469, -0.1112,  0.9017],\n",
            "        [ 0.7496, -0.1232,  0.6312,  ...,  0.6909,  0.0641,  1.4927],\n",
            "        [ 0.4377,  0.5227,  1.3720,  ...,  1.3790,  0.1214, -1.5727]])\n"
          ]
        }
      ],
      "source": [
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0hiZeN9FZun"
      },
      "source": [
        "### pad는 pad_idx 옵션 때문에 훈련 내내 0으로 남아있지만 unk는 학습될 것!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgnvNF3GmvIc"
      },
      "source": [
        "# 모델 학습\n",
        "> adam으로 학습 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8Ei3Yi1FFgoz"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoLU1wVqF41v"
      },
      "source": [
        "### 손실 함수는 binary cross entropy with logits로 하자. 이 함수는 임의의 실수를 입력으로 받아서 sigmoid 함수를 취해 0과 1 사이의 값으로 변환한 뒤 label과의 binary cross entropy를 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QV20RV_uFguq"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNnsOjOdFg1J"
      },
      "source": [
        "### 평가를 위해 임의의 실수를 0과 1 두 정수 중 하나로 변환하는 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bxsLMkj1GC1Y"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds==y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC3lZ8U0GER9"
      },
      "source": [
        "### 훈련 함수. 현재 batch.text 는 (토큰들,문장 길이) 로 구성되어 있으니 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "hJvd-wlFGHem"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        #print(batch.text)\n",
        "        text, text_lengths = batch.text\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        #print_shape('predictions',predictions)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        #print_shape('loss',loss)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        print(f\"epoch_loss / len(iterator) : {epoch_loss / len(iterator)}\")\n",
        "        print(f\"epoch_acc / len(iterator) : {epoch_acc / len(iterator)}\")\n",
        "        \n",
        "        return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDokJdW5GLNd"
      },
      "source": [
        "### 평가를 위한 함수는 그래디언트 업데이트를 하지 않아야 하므로 with torch.no_grad(): 구문으로 감싸도록 한다. 또한 드랍아웃을 평가 때는 적용하지 않아야 하므로 model.eval() 을 넣어주어야 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "4sk3YzxaGNs7"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)#.squeeze(0))\n",
        "            acc = binary_accuracy(predictions, batch.label)#.squeeze(0))\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "        return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3ypgmA1GOkg"
      },
      "source": [
        "### 에폭마다 걸린 훈련시간을 측정하는 함수 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "xoQBlk5EGR4B"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWYVsAQGG2yN"
      },
      "source": [
        "### 훈련 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vvJH4wQhG4P5",
        "outputId": "d05034bb-a529-45ff-e92e-4f2d72a6e236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch_loss / len(iterator) : -0.001713441193469463\n",
            "epoch_acc / len(iterator) : 0.0011023773006134969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:24<03:36, 24.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 23s\n",
            "\tTrain Loss: -0.002 | Train Acc: 0.11%\n",
            "\t Val. Loss: -0.568 |  Val. Acc: 38.92%\n",
            "epoch_loss / len(iterator) : 0.0009915876242280737\n",
            "epoch_acc / len(iterator) : 0.0015337423312883436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:52<03:31, 26.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 02 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.001 | Train Acc: 0.15%\n",
            "\t Val. Loss: -0.643 |  Val. Acc: 39.28%\n",
            "epoch_loss / len(iterator) : -0.0027095931439311957\n",
            "epoch_acc / len(iterator) : 0.0017254601226993865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [01:16<02:57, 25.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 03 | Epoch Time: 0m 23s\n",
            "\tTrain Loss: -0.003 | Train Acc: 0.17%\n",
            "\t Val. Loss: -0.700 |  Val. Acc: 39.39%\n",
            "epoch_loss / len(iterator) : 0.00096199629496943\n",
            "epoch_acc / len(iterator) : 0.0012940950920245398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:42<02:34, 25.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 04 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.001 | Train Acc: 0.13%\n",
            "\t Val. Loss: -0.750 |  Val. Acc: 39.63%\n",
            "epoch_loss / len(iterator) : -0.0023948237574173627\n",
            "epoch_acc / len(iterator) : 0.0012940950920245398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [02:06<02:05, 25.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 05 | Epoch Time: 0m 23s\n",
            "\tTrain Loss: -0.002 | Train Acc: 0.13%\n",
            "\t Val. Loss: -0.824 |  Val. Acc: 39.78%\n",
            "epoch_loss / len(iterator) : -0.0009544324472637995\n",
            "epoch_acc / len(iterator) : 0.0011982361963190184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [02:32<01:41, 25.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 06 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: -0.001 | Train Acc: 0.12%\n",
            "\t Val. Loss: -0.936 |  Val. Acc: 40.09%\n",
            "epoch_loss / len(iterator) : -0.0024957700741071644\n",
            "epoch_acc / len(iterator) : 0.0011982361963190184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [02:54<01:13, 24.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 07 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: -0.002 | Train Acc: 0.12%\n",
            "\t Val. Loss: -1.041 |  Val. Acc: 40.29%\n",
            "epoch_loss / len(iterator) : 0.0024334000297850625\n",
            "epoch_acc / len(iterator) : 0.0013899539877300613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [03:19<00:49, 24.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 08 | Epoch Time: 0m 24s\n",
            "\tTrain Loss: 0.002 | Train Acc: 0.14%\n",
            "\t Val. Loss: -1.163 |  Val. Acc: 40.90%\n",
            "epoch_loss / len(iterator) : -0.000987282742751888\n",
            "epoch_acc / len(iterator) : 0.0018213190184049079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [03:44<00:24, 24.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 09 | Epoch Time: 0m 24s\n",
            "\tTrain Loss: -0.001 | Train Acc: 0.18%\n",
            "\t Val. Loss: -1.188 |  Val. Acc: 40.94%\n",
            "epoch_loss / len(iterator) : -0.006386086253300767\n",
            "epoch_acc / len(iterator) : 0.0006230828220858896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [04:12<00:00, 25.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: -0.006 | Train Acc: 0.06%\n",
            "\t Val. Loss: -1.231 |  Val. Acc: 41.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n[torchtext.legacy.data.batch.Batch of size 64]\\n\\t[.text]:[torch.LongTensor of size 8x64]\\n\\t[.label]:[torch.FloatTensor of size 64]\\n  \"batch.text becomes a 2-element tuple when we use include_lengths = True in our TEXT field.\"\\n  => If you do not want to use packed padded sequences, then change text, text_lengths = batch.text to text = batch.text\\n  and remove all references to text_lengths. If you do want to use packed padded sequences, \\n  you need include_lengths set to True in your TEXT field\\n  https://github.com/bentrevett/pytorch-sentiment-analysis/issues/38\\n  https://bobbyhadz.com/blog/python-valueerror-too-many-values-to-unpack-expected-2\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "from tqdm import tqdm \n",
        "\n",
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in tqdm(range(N_EPOCHS)):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "        \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "# 발생한 에러 ValueError: too many values to unpack (expected 2)\n",
        "# 이 에러의 의미는 설정한 변수의 개수와 리턴해 주는 변수의 개수가 차이가 날 때 발생한다. \n",
        "\"\"\"\n",
        "[torchtext.legacy.data.batch.Batch of size 64]\n",
        "\t[.text]:[torch.LongTensor of size 8x64]\n",
        "\t[.label]:[torch.FloatTensor of size 64]\n",
        "  \"batch.text becomes a 2-element tuple when we use include_lengths = True in our TEXT field.\"\n",
        "  => If you do not want to use packed padded sequences, then change text, text_lengths = batch.text to text = batch.text\n",
        "  and remove all references to text_lengths. If you do want to use packed padded sequences, \n",
        "  you need include_lengths set to True in your TEXT field\n",
        "  https://github.com/bentrevett/pytorch-sentiment-analysis/issues/38\n",
        "  https://bobbyhadz.com/blog/python-valueerror-too-many-values-to-unpack-expected-2\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMqj21n1HBjL"
      },
      "source": [
        "### 테스트셋의 결과"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGjDwehFHC4P",
        "outputId": "18576cdc-4304-472f-b481-80c29f4136ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: -1.143 | Test Acc: 41.59%\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu61xq10nEII"
      },
      "source": [
        "# 사용자 데이터 사용\n",
        "영화 평가 데이터 직접 넣어보자.\n",
        "\n",
        "다음 기능을 하는 predict_sentiment 함수를 만들자.\n",
        "\n",
        "sets the model to evaluation mode\n",
        "tokenizes the sentence, i.e. splits it from a raw string into a list of tokens\n",
        "indexes the tokens by converting them into their integer representation from our vocabulary\n",
        "gets the length of our sequence\n",
        "converts the indexes, which are a Python list into a PyTorch tensor\n",
        "add a batch dimension by unsqueezeing\n",
        "converts the length into a tensor\n",
        "squashes the output prediction from a real number between 0 and 1 with the sigmoid function\n",
        "converts the tensor holding a single value into an integer with the item() method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "TrsGoFe2m3J_"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "d6v7lNFzm36e"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok for tok in mecab.morphs(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1) # 배치 \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "XF3rq3-Zm4Cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf86a901-ca91-4571-a2ed-52623ec88982"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999994039535522"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "predict_sentiment(model, \"이 영화 진짜 재밌었다!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Dj-BhKMOm4Ic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "014feaa1-9245-4c03-e19b-00ad8ec02064"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33895620703697205"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "predict_sentiment(model, \"최악이야!!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(model, \"괜히 봤음. 내 돈 돌려주세요ㅠ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLv6iHQp6x6V",
        "outputId": "600dae09-a4e1-46b6-f34f-17b2f3106cc8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6688205003738403"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(model, \"그냥그랬음\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jy_FwyO61sK",
        "outputId": "a31dc054-06d7-4281-ba5c-3c0a160a19fc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3783482015132904"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(model, \"내 인생 영화\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV8ZNmjy650y",
        "outputId": "d054f223-5b80-4100-8416-9d445267c3a8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9537668228149414"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGf0BzhL7yOtlKDEihx2hx",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}